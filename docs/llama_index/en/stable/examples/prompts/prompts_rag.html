LlamaIndex 🦙 0.8.68 Search Search ⌘K Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes v: stable Back to top Edit this page  !      import os import openai  os . environ [ "OPENAI_API_KEY" ] = "sk-..." openai . api_key = os . environ [ "OPENAI_API_KEY" ]  import logging import sys logging . basicConfig ( stream = sys . stdout , level = logging . INFO ) logging . getLogger () . addHandler ( logging . StreamHandler ( stream = sys . stdout )) from llama_index import VectorStoreIndex from llama_index.prompts import PromptTemplate from IPython.display import Markdown , display   !   !     "Mozilla"   "https://arxiv.org/pdf/2307.09288.pdf"     "data/llama2.pdf"   from pathlib import Path from llama_hub.file.pymu_pdf.base import PyMuPDFReader  loader = PyMuPDFReader () documents = loader . load ( file_path = "./data/llama2.pdf" )  from llama_index import VectorStoreIndex , ServiceContext from llama_index.llms import OpenAI gpt35_llm = OpenAI ( model = "gpt-3.5-turbo" ) gpt4_llm = OpenAI ( model = "gpt-4" ) service_context = ServiceContext . from_defaults ( chunk_size = 1024 , llm = gpt35_llm ) index = VectorStoreIndex . from_documents ( documents , service_context = service_context )  query_str = "What are the potential risks associated with the use of Llama 2 as mentioned in the context?"  query_engine = index . as_query_engine ( similarity_top_k = 2 ) # use this for testing vector_retriever = index . as_retriever ( similarity_top_k = 2 )  response = query_engine . query ( query_str ) print ( str ( response ))   # define prompt viewing function def display_prompt_dict ( prompts_dict ): for k , p in prompts_dict . items (): text_md = f "**Prompt Key**:  { k } <br>" f "**Text:** <br>" display ( Markdown ( text_md )) print ( p . get_template ()) display ( Markdown ( "<br><br>" ))  prompts_dict = query_engine . get_prompts ()  display_prompt_dict ( prompts_dict )    # to do this, you need to use the langchain object from langchain import hub langchain_prompt = hub . pull ( "rlm/rag-prompt" ) context question context_str query_str LangchainPromptTemplate  from llama_index.prompts import LangchainPromptTemplate lc_prompt_tmpl = LangchainPromptTemplate ( template = langchain_prompt , template_var_mappings = { "query_str" : "question" , "context_str" : "context" }, ) query_engine . update_prompts ( { "response_synthesizer:text_qa_template" : lc_prompt_tmpl } )  prompts_dict = query_engine . get_prompts () display_prompt_dict ( prompts_dict )    response = query_engine . query ( query_str ) print ( str ( response ))  function_mapping  { "query" : "<query>" , "response" : "<output_json>" }  from llama_index.schema import TextNode few_shot_nodes = [] for line in open ( "../llama2_qa_citation_events.jsonl" , "r" ): few_shot_nodes . append ( TextNode ( text = line )) few_shot_index = VectorStoreIndex ( few_shot_nodes ) few_shot_retriever = few_shot_index . as_retriever ( similarity_top_k = 2 )  import json def few_shot_examples_fn ( ** kwargs ): query_str = kwargs [ "query_str" ] retrieved_nodes = few_shot_retriever . retrieve ( query_str ) # go through each node, get json object result_strs = [] for n in retrieved_nodes : raw_dict = json . loads ( n . get_content ()) query = raw_dict [ "query" ] response_dict = json . loads ( raw_dict [ "response" ]) result_str = f """ \ Query:  { query } Response:  { response_dict } """ result_strs . append ( result_str ) return " \n\n " . join ( result_strs )  # write prompt template with functions qa_prompt_tmpl_str = """ \ Context information is below. --------------------- {context_str} --------------------- Given the context information and not prior knowledge,  \ answer the query asking about citations over different topics. Please provide your answer in the form of a structured JSON format containing  \ a list of authors as the citations. Some examples are given below. {few_shot_examples} Query:  {query_str} Answer:  \ """ qa_prompt_tmpl = PromptTemplate ( qa_prompt_tmpl_str , function_mappings = { "few_shot_examples" : few_shot_examples_fn }, )  citation_query_str = ( "Which citations are mentioned in the section on Safety RLHF?" )  print ( qa_prompt_tmpl . format ( query_str = citation_query_str , context_str = "test_context" ) )   query_engine . update_prompts ( { "response_synthesizer:text_qa_template" : qa_prompt_tmpl } )  display_prompt_dict ( query_engine . get_prompts ())    response = query_engine . query ( citation_query_str ) print ( str ( response ))   print ( response . source_nodes [ 1 ] . get_content ()) context_str  from llama_index.indices.postprocessor import ( NERPIINodePostprocessor , SentenceEmbeddingOptimizer , ) from llama_index import ServiceContext from llama_index.indices.query.schema import QueryBundle from llama_index.schema import NodeWithScore , TextNode  service_context = ServiceContext . from_defaults ( llm = gpt4_llm ) pii_processor = NERPIINodePostprocessor ( service_context = service_context )  def filter_pii_fn ( ** kwargs ): # run optimizer query_bundle = QueryBundle ( query_str = kwargs [ "query_str" ]) new_nodes = pii_processor . postprocess_nodes ( [ NodeWithScore ( node = TextNode ( text = kwargs [ "context_str" ]))], query_bundle = query_bundle , ) new_node = new_nodes [ 0 ] return new_node . get_content ()  qa_prompt_tmpl_str = ( "Context information is below. \n " "--------------------- \n " " {context_str} \n " "--------------------- \n " "Given the context information and not prior knowledge, " "answer the query. \n " "Query:  {query_str} \n " "Answer: " ) qa_prompt_tmpl = PromptTemplate ( qa_prompt_tmpl_str , function_mappings = { "context_str" : filter_pii_fn } )  query_engine . update_prompts ( { "response_synthesizer:text_qa_template" : qa_prompt_tmpl } )  # take a look at the prompt retrieved_nodes = vector_retriever . retrieve ( query_str ) context_str = " \n\n " . join ([ n . get_content () for n in retrieved_nodes ])  print ( qa_prompt_tmpl . format ( query_str = query_str , context_str = context_str ))  response = query_engine . query ( query_str ) print ( str ( response )) Next Previous On this page context question context_str query_str LangchainPromptTemplate function_mapping context_str Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes  In this notebook we show various prompt techniques you can try to customize your LlamaIndex RAG pipeline. Getting and setting prompts for query engines, etc. Defining template variable mappings (e.g. you have an existing QA prompt) Adding few-shot examples + performing query transformations/rewriting. First, let’s take a look at the query engine prompts, and see how we can customize it. Prompt Key: response_synthesizer:text_qa_templateText:   Prompt Key: response_synthesizer:refine_templateText:   What if we want to do something different than our standard question-answering prompts? Let’s try out the RAG prompt from LangchainHub One catch is that the template variables in the prompt are different than what’s expected by our synthesizer in the query engine: the prompt uses context and question, we expect context_str and query_str This is not a problem! Let’s add our template variable mappings to map variables. We use our LangchainPromptTemplate to map to LangChain prompts. Prompt Key: response_synthesizer:text_qa_templateText:   Prompt Key: response_synthesizer:refine_templateText:   Let’s re-run our query engine again. Let’s try adding few-shot examples to the prompt, which can be dynamically loaded depending on the query! We do this by setting the function_mapping variable in our prompt template - this allows us to compute functions (e.g. return few-shot examples) during prompt formatting time. As an example use case, through this we can coerce the model to output results in a structured format, by showing examples of other structured outputs. Let’s parse a pre-generated question/answer file. For the sake of focus we’ll skip how the file is generated (tl;dr we used a GPT-4 powered function calling RAG pipeline), but the qa pairs look like this: We embed/index these Q/A pairs, and retrieve the top-k. Let’s see what the formatted prompt looks like with the few-shot examples function. (we fill in test context for brevity) Prompt Key: response_synthesizer:text_qa_templateText:   Prompt Key: response_synthesizer:refine_templateText:   We can also dynamically add context transformations as functions in the prompt variable. In this example we show how we can process the context_str before feeding to the context window - specifically in masking out PII (a step towards alleviating concerns around data privacy/security). NOTE: You can do these as steps before feeding into the prompt as well, but this gives you flexibility to perform all this on the fly for any QA prompt you define! 🦙 !pip install llama-index import os import openai os.environ["OPENAI_API_KEY"] = "sk-..." openai.api_key = os.environ["OPENAI_API_KEY"] import logging import sys logging.basicConfig(stream=sys.stdout, level=logging.INFO) logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout)) from llama_index import VectorStoreIndex from llama_index.prompts import PromptTemplate from IPython.display import Markdown, display INFO:numexpr.utils:Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8. Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8. INFO:numexpr.utils:NumExpr defaulting to 8 threads. NumExpr defaulting to 8 threads. !mkdir data !wget --user-agent "Mozilla" "https://arxiv.org/pdf/2307.09288.pdf" -O "data/llama2.pdf" mkdir: data: File exists --2023-10-28 23:19:38--  https://arxiv.org/pdf/2307.09288.pdf Resolving arxiv.org (arxiv.org)... 128.84.21.199 Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 13661300 (13M) [application/pdf] Saving to: ‘data/llama2.pdf’ data/llama2.pdf     100%[===================>]  13.03M  1.50MB/s    in 10s 2023-10-28 23:19:49 (1.31 MB/s) - ‘data/llama2.pdf’ saved [13661300/13661300] from pathlib import Path from llama_hub.file.pymu_pdf.base import PyMuPDFReader loader = PyMuPDFReader() documents = loader.load(file_path="./data/llama2.pdf") from llama_index import VectorStoreIndex, ServiceContext from llama_index.llms import OpenAI gpt35_llm = OpenAI(model="gpt-3.5-turbo") gpt4_llm = OpenAI(model="gpt-4") service_context = ServiceContext.from_defaults(chunk_size=1024, llm=gpt35_llm) index = VectorStoreIndex.from_documents( documents, service_context=service_context ) query_str = "What are the potential risks associated with the use of Llama 2 as mentioned in the context?" query_engine = index.as_query_engine(similarity_top_k=2) # use this for testing vector_retriever = index.as_retriever(similarity_top_k=2) response = query_engine.query(query_str) print(str(response)) The potential risks associated with the use of Llama 2, as mentioned in the context, include the generation of misinformation and the retrieval of information about topics such as bioterrorism or cybercrime. The models have been tuned to avoid these topics and diminish any capabilities they might have offered for those use cases. However, there is a possibility that the safety tuning of the models may go too far, resulting in an overly cautious approach where the model declines certain requests or responds with too many safety details. Users of Llama 2 and Llama 2-Chat need to be cautious and take extra steps in tuning and deployment to ensure responsible use. # define prompt viewing function def display_prompt_dict(prompts_dict): for k, p in prompts_dict.items(): text_md = f"**Prompt Key**: {k}<br>" f"**Text:** <br>" display(Markdown(text_md)) print(p.get_template()) display(Markdown("<br><br>")) prompts_dict = query_engine.get_prompts() display_prompt_dict(prompts_dict) Context information is below. --------------------- {context_str} Given the context information and not prior knowledge, answer the query. Query: {query_str} Answer: The original query is as follows: {query_str} We have provided an existing answer: {existing_answer} We have the opportunity to refine the existing answer (only if needed) with some more context below. ------------ {context_msg} Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer. Refined Answer: # to do this, you need to use the langchain object from langchain import hub langchain_prompt = hub.pull("rlm/rag-prompt") from llama_index.prompts import LangchainPromptTemplate lc_prompt_tmpl = LangchainPromptTemplate( template=langchain_prompt, template_var_mappings={"query_str": "question", "context_str": "context"}, query_engine.update_prompts( {"response_synthesizer:text_qa_template": lc_prompt_tmpl} input_variables=['question', 'context'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'context'], template="You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\nQuestion: {question} \nContext: {context} \nAnswer:"))] The potential risks associated with the use of Llama 2 mentioned in the context include the generation of misinformation, retrieval of information about topics like bioterrorism or cybercrime, an overly cautious approach by the model, and the need for users to be cautious and take extra steps in tuning and deployment. However, efforts have been made to tune the models to avoid these topics and diminish any capabilities they might have offered for those use cases. {"query": "<query>", "response": "<output_json>"} from llama_index.schema import TextNode few_shot_nodes = [] for line in open("../llama2_qa_citation_events.jsonl", "r"): few_shot_nodes.append(TextNode(text=line)) few_shot_index = VectorStoreIndex(few_shot_nodes) few_shot_retriever = few_shot_index.as_retriever(similarity_top_k=2) import json def few_shot_examples_fn(**kwargs): query_str = kwargs["query_str"] retrieved_nodes = few_shot_retriever.retrieve(query_str) # go through each node, get json object result_strs = [] for n in retrieved_nodes: raw_dict = json.loads(n.get_content()) query = raw_dict["query"] response_dict = json.loads(raw_dict["response"]) result_str = f"""\ Query: {query} Response: {response_dict}""" result_strs.append(result_str) return "\n\n".join(result_strs) # write prompt template with functions qa_prompt_tmpl_str = """\ Given the context information and not prior knowledge, \ answer the query asking about citations over different topics. Please provide your answer in the form of a structured JSON format containing \ a list of authors as the citations. Some examples are given below. {few_shot_examples} Answer: \ """ qa_prompt_tmpl = PromptTemplate( qa_prompt_tmpl_str, function_mappings={"few_shot_examples": few_shot_examples_fn}, citation_query_str = ( "Which citations are mentioned in the section on Safety RLHF?" print( qa_prompt_tmpl.format( query_str=citation_query_str, context_str="test_context" test_context Given the context information and not prior knowledge, answer the query asking about citations over different topics. Please provide your answer in the form of a structured JSON format containing a list of authors as the citations. Some examples are given below. Query: Which citation discusses the impact of safety RLHF measured by reward model score distributions? Response: {'citations': [{'author': 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'year': 24, 'desc': 'Impact of safety RLHF measured by reward model score distributions. Left: safety reward model scores of generations on the Meta Safety test set. The clustering of samples in the top left corner suggests the improvements of model safety. Right: helpfulness reward model scores of generations on the Meta Helpfulness test set.'}]} Query: Which citations are mentioned in the section on RLHF Results? Response: {'citations': [{'author': 'Gilardi et al.', 'year': 2023, 'desc': ''}, {'author': 'Huang et al.', 'year': 2023, 'desc': ''}]} Query: Which citations are mentioned in the section on Safety RLHF? {"response_synthesizer:text_qa_template": qa_prompt_tmpl} display_prompt_dict(query_engine.get_prompts()) response = query_engine.query(citation_query_str) {'citations': [{'author': 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'year': 24, 'desc': 'Safety RLHF'}, {'author': 'Bai et al.', 'year': 2022a, 'desc': 'RLHF stage'}, {'author': 'Bai et al.', 'year': 2022a, 'desc': 'adversarial prompts'}, {'author': 'Bai et al.', 'year': 2022a, 'desc': 'safety reward model'}, {'author': 'Bai et al.', 'year': 2022a, 'desc': 'helpfulness reward model'}, {'author': 'Bai et al.', 'year': 2022a, 'desc': 'safety tuning with RLHF'}]} print(response.source_nodes[1].get_content()) from llama_index.indices.postprocessor import ( NERPIINodePostprocessor, SentenceEmbeddingOptimizer, from llama_index import ServiceContext from llama_index.indices.query.schema import QueryBundle from llama_index.schema import NodeWithScore, TextNode service_context = ServiceContext.from_defaults(llm=gpt4_llm) pii_processor = NERPIINodePostprocessor(service_context=service_context) def filter_pii_fn(**kwargs): # run optimizer query_bundle = QueryBundle(query_str=kwargs["query_str"]) new_nodes = pii_processor.postprocess_nodes( [NodeWithScore(node=TextNode(text=kwargs["context_str"]))], query_bundle=query_bundle, new_node = new_nodes[0] return new_node.get_content() qa_prompt_tmpl_str = ( "Context information is below.\n" "---------------------\n" "{context_str}\n" "Given the context information and not prior knowledge, " "answer the query.\n" "Query: {query_str}\n" "Answer: " qa_prompt_tmpl_str, function_mappings={"context_str": filter_pii_fn} # take a look at the prompt retrieved_nodes = vector_retriever.retrieve(query_str) context_str = "\n\n".join([n.get_content() for n in retrieved_nodes]) print(qa_prompt_tmpl.format(query_str=query_str, context_str=context_str)) Prompt Engineering for RAG Setup Viewing/Customizing Prompts Adding Few-Shot Examples Context Transformations - PII Example Load Data Load into Vector Store Setup Query Engine / Retriever View Prompts Customize Prompts Try It Out Installation and Setup How to read these docs Starter Tutorial High-Level Concepts Customization Tutorial Discover LlamaIndex Video Series Q&A Chatbots Agents Structured Data Extraction Multi-modalToggle child pages in navigation Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever Multi-modal retrieval with CLIP Retrieval-Augmented Image Captioning Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever Multi-modal retrieval with CLIP Retrieval-Augmented Image Captioning Building an LLM application Using LLMsToggle child pages in navigation Privacy and Security Privacy and Security LoadingToggle child pages in navigation LlamaHub LlamaHub Indexing Storing Querying Putting It All TogetherToggle child pages in navigation Q&A patternsToggle child pages in navigation A Guide to Extracting Terms and Definitions A Guide to Creating a Unified Query Framework over your Indexes Knowledge Graphs Structured Data A Guide to LlamaIndex + Structured Data Airbyte SQL Index Guide Full-Stack Web ApplicationToggle child pages in navigation A Guide to Building a Full-Stack Web App with LLamaIndex A Guide to Building a Full-Stack LlamaIndex Web App with Delphic How to Build a Chatbot Agents A Guide to Extracting Terms and Definitions A Guide to Creating a Unified Query Framework over your Indexes Knowledge Graphs Structured Data A Guide to LlamaIndex + Structured Data Airbyte SQL Index Guide Full-Stack Web ApplicationToggle child pages in navigation A Guide to Building a Full-Stack Web App with LLamaIndex A Guide to Building a Full-Stack LlamaIndex Web App with Delphic How to Build a Chatbot Agents Tracing and Debugging EvaluatingToggle child pages in navigation Cost AnalysisToggle child pages in navigation Usage Pattern Usage Pattern Basic StrategiesToggle child pages in navigation Accessing/Customizing Prompts within Higher-Level Modules Advanced Prompt Techniques (Variable Mappings, Functions) Prompt Engineering for RAG BM25 Retriever Reciprocal Rerank Fusion Retriever Weaviate Vector Store - Hybrid Search Pinecone Vector Store - Hybrid Search Vector Store Index Defining and Customizing DocumentsToggle child pages in navigation Extracting Metadata for Better Document Indexing and Understanding Defining and Customizing Nodes Automated Metadata Extraction for NodesToggle child pages in navigation Automated Metadata Extraction for Better Retrieval + Synthesis Entity Metadata Extraction Metadata Extraction and Augmentation w/ Marvin Pydantic Extractor Accessing/Customizing Prompts within Higher-Level Modules Advanced Prompt Techniques (Variable Mappings, Functions) Advanced Prompt Techniques (Variable Mappings, Functions) Prompt Engineering for RAG BM25 Retriever Reciprocal Rerank Fusion Retriever Weaviate Vector Store - Hybrid Search Pinecone Vector Store - Hybrid Search Vector Store Index Defining and Customizing DocumentsToggle child pages in navigation Extracting Metadata for Better Document Indexing and Understanding Defining and Customizing Nodes Automated Metadata Extraction for NodesToggle child pages in navigation Extracting Metadata for Better Document Indexing and Understanding Automated Metadata Extraction for Better Retrieval + Synthesis Entity Metadata Extraction Metadata Extraction and Augmentation w/ Marvin Pydantic Extractor Advanced Retrieval StrategiesToggle child pages in navigation Query TransformationsToggle child pages in navigation HyDE Query Transform Multi-Step Query Engine Pydantic ProgramToggle child pages in navigation OpenAI Pydantic Program Guidance Pydantic Program Guidance for Sub-Question Query Engine DataFrame Structured Data Extraction Evaporate Demo Query Engines + Pydantic OutputsToggle child pages in navigation Query Engine with Pydantic Outputs Pydantic Tree Summarize Download Data Structured OutputsToggle child pages in navigation DeepMemory (Activeloop) HyDE Query Transform Multi-Step Query Engine Pydantic ProgramToggle child pages in navigation OpenAI Pydantic Program Guidance Pydantic Program Guidance for Sub-Question Query Engine DataFrame Structured Data Extraction Evaporate Demo Query Engines + Pydantic OutputsToggle child pages in navigation Query Engine with Pydantic Outputs Pydantic Tree Summarize Download Data Structured OutputsToggle child pages in navigation Query Engine with Pydantic Outputs Pydantic Tree Summarize Download Data DeepMemory (Activeloop) Agentic strategiesToggle child pages in navigation Build your own OpenAI Agent OpenAI Agent with Query Engine Tools Retrieval-Augmented OpenAI Agent OpenAI Agent + Query Engine Experimental Cookbook OpenAI Agent Query Planning Context-Augmented OpenAI Agent Build your own OpenAI Agent OpenAI Agent with Query Engine Tools Retrieval-Augmented OpenAI Agent OpenAI Agent + Query Engine Experimental Cookbook OpenAI Agent Query Planning Context-Augmented OpenAI Agent EvaluationToggle child pages in navigation End-to-End EvaluationToggle child pages in navigation QuestionGeneration BatchEvalRunner - Running Multiple Evaluations Correctness Evaluator Faithfulness Evaluator Guideline Evaluator Pairwise Evaluator Relevancy Evaluator Embedding Similarity Evaluator Component Wise EvaluationToggle child pages in navigation BEIR Out of Domain Benchmark HotpotQADistractor Demo EvaluatingToggle child pages in navigation Usage Pattern (Response Evaluation) Usage Pattern (Retrieval) ModulesToggle child pages in navigation LlamaIndex + DeepEval Integration Retrieval Evaluation QuestionGeneration BatchEvalRunner - Running Multiple Evaluations Correctness Evaluator Faithfulness Evaluator Guideline Evaluator Pairwise Evaluator Relevancy Evaluator Embedding Similarity Evaluator Component Wise EvaluationToggle child pages in navigation BEIR Out of Domain Benchmark HotpotQADistractor Demo EvaluatingToggle child pages in navigation Usage Pattern (Response Evaluation) Usage Pattern (Retrieval) ModulesToggle child pages in navigation Faithfulness Evaluator Relevancy Evaluator Guideline Evaluator Correctness Evaluator Embedding Similarity Evaluator LlamaIndex + DeepEval Integration QuestionGeneration BatchEvalRunner - Running Multiple Evaluations Retrieval Evaluation Component Wise EvaluationToggle child pages in navigation BEIR Out of Domain Benchmark HotpotQADistractor Demo End-to-End EvaluationToggle child pages in navigation QuestionGeneration BatchEvalRunner - Running Multiple Evaluations Correctness Evaluator Faithfulness Evaluator Guideline Evaluator Pairwise Evaluator Relevancy Evaluator Embedding Similarity Evaluator Fine-tuningToggle child pages in navigation Fine-tuning an Adapter Embedding Fine-tuning Guide Router Fine-tuning Embedding Fine-tuning Repo Embedding Fine-tuning Blog GPT-3.5 Fine-tuning Notebook (Colab) GPT-3.5 Fine-tuning Notebook (Notebook link) Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought [WIP] Function Calling Fine-tuning GPT-3.5 Fine-tuning Notebook (in Repo) Fine-tuning with Retrieval Augmentation OpenAI Function Calling Fine-tuning Llama2 Structured Output Fine-tuning Fine-tuning to Memorize Knowledge Llama 2 Text-to-SQL Fine-tuning (w/ Gradient.AI) Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Repo) Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Notebook) Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness) Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise) Cross-Encoder Finetuning Finetuning Llama 2 for Text-to-SQL Finetuning GPT-3.5 to Distill GPT-4 Fine-tuning an Adapter Embedding Fine-tuning Guide Router Fine-tuning Embedding Fine-tuning Repo Embedding Fine-tuning Blog GPT-3.5 Fine-tuning Notebook (Colab) GPT-3.5 Fine-tuning Notebook (Notebook link) Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought [WIP] Function Calling Fine-tuning GPT-3.5 Fine-tuning Notebook (Colab) GPT-3.5 Fine-tuning Notebook (in Repo) Fine-tuning with Retrieval Augmentation OpenAI Function Calling Fine-tuning Llama2 Structured Output Fine-tuning Fine-tuning to Memorize Knowledge Llama 2 Text-to-SQL Fine-tuning (w/ Gradient.AI) Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Repo) Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Notebook) Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness) Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise) Cross-Encoder Finetuning Finetuning Llama 2 for Text-to-SQL Finetuning GPT-3.5 to Distill GPT-4 Building Performant RAG Applications for ProductionToggle child pages in navigation Recursive Retriever + Query Engine Demo Document Summary Index Metadata Replacement + Node Sentence Window Auto-Retrieval from a Vector Database Recursive Retriever + Document Agents Comparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval) Sub Question Query Engine Joint QA Summary Query Engine Router Query Engine Recursive Retriever + Query Engine Demo Document Summary Index Metadata Replacement + Node Sentence Window Auto-Retrieval from a Vector Database Document Summary Index Recursive Retriever + Document Agents Comparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval) Sub Question Query Engine Joint QA Summary Query Engine Recursive Retriever + Document Agents Router Query Engine OpenAI Agent + Query Engine Experimental Cookbook OpenAI Agent Query Planning Embedding Fine-tuning Guide Building RAG from Scratch (Lower-Level)Toggle child pages in navigation Building Data Ingestion from Scratch Pinecone OpenAI Building Retrieval from Scratch Building RAG from Scratch (Open-source only!) Building a (Very Simple) Vector Store from Scratch Building Response Synthesis from Scratch Building Evaluation from Scratch Building a Router from Scratch Building an Advanced Fusion Retriever from Scratch Building Data Ingestion from Scratch Pinecone OpenAI Building Retrieval from Scratch Building RAG from Scratch (Open-source only!) Building a (Very Simple) Vector Store from Scratch Building Response Synthesis from Scratch Building Evaluation from Scratch Building a Router from Scratch Building an Advanced Fusion Retriever from Scratch ModelsToggle child pages in navigation Using LLMsToggle child pages in navigation Using LLMs as standalone modules Customizing LLMs within LlamaIndex Abstractions Available LLM integrationsToggle child pages in navigation Azure OpenAI AI21 Anthropic Gradient Base Model Gradient Model Adapter HuggingFace LLM - Camel-5b HuggingFace LLM - StableLM Local Llama2 + VectorStoreIndex EverlyAI LiteLLM PaLM Predibase Replicate - Llama 2 13B Replicate - Vicuna 13B Llama2 + VectorStoreIndex LangChain LLM Llama API LlamaCPP Xorbits Inference Monster API LLM Integration into LLamaIndex RunGPT Setup Portkey Anyscale Ollama - Llama 2 7B Clarifai LLM Bedrock Connect to Bedrock with Access Keysfrom llama_index.llms import Bedrock Getting Started Streaming Usage Chat Usage Async Chat Streaming Chat EmbeddingsToggle child pages in navigation OpenAI Embeddings Langchain Embeddings CohereAI Embeddings Gradient Embeddings Custom Embeddings Local Embeddings with HuggingFace Elasticsearch Embeddings Embeddings with Clarifai LLMRails Embeddings Text Embedding Inference Google PaLM Embeddings Jina Embeddings PromptsToggle child pages in navigation Completion prompts Chat prompts “Optimization by Prompting” for RAG EmotionPrompt in RAG Using local models Run Llama2 locally [Beta] Multi-modal modelsToggle child pages in navigation Multi-Modal LLM using OpenAI GPT-4V model for image reasoning Multi-Modal LLM using Replicate LlaVa and Fuyu 8B model for image reasoning Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles Using LLMs as standalone modules Customizing LLMs within LlamaIndex Abstractions Available LLM integrationsToggle child pages in navigation OpenAI Azure OpenAI AI21 Anthropic Gradient Base Model Gradient Model Adapter HuggingFace LLM - Camel-5b HuggingFace LLM - StableLM Local Llama2 + VectorStoreIndex EverlyAI LiteLLM PaLM Predibase Replicate - Llama 2 13B Replicate - Vicuna 13B Llama2 + VectorStoreIndex LangChain LLM Llama API LlamaCPP Xorbits Inference Monster API LLM Integration into LLamaIndex RunGPT Setup Portkey Anyscale Ollama - Llama 2 7B Clarifai LLM Bedrock Connect to Bedrock with Access Keysfrom llama_index.llms import Bedrock Getting Started Streaming Usage Chat Usage Async Chat Streaming Chat EmbeddingsToggle child pages in navigation OpenAI Embeddings Langchain Embeddings CohereAI Embeddings Gradient Embeddings Azure OpenAI Custom Embeddings Local Embeddings with HuggingFace Elasticsearch Embeddings Embeddings with Clarifai LLMRails Embeddings Text Embedding Inference Google PaLM Embeddings Jina Embeddings PromptsToggle child pages in navigation Usage Pattern Completion prompts Chat prompts Accessing/Customizing Prompts within Higher-Level Modules Advanced Prompt Techniques (Variable Mappings, Functions) Prompt Engineering for RAG “Optimization by Prompting” for RAG EmotionPrompt in RAG Using local models Run Llama2 locally EmbeddingsToggle child pages in navigation OpenAI Embeddings Langchain Embeddings CohereAI Embeddings Gradient Embeddings Azure OpenAI Custom Embeddings Local Embeddings with HuggingFace Elasticsearch Embeddings Embeddings with Clarifai LLMRails Embeddings Text Embedding Inference Google PaLM Embeddings Jina Embeddings [Beta] Multi-modal modelsToggle child pages in navigation Multi-Modal LLM using OpenAI GPT-4V model for image reasoning Multi-Modal LLM using Replicate LlaVa and Fuyu 8B model for image reasoning Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles Retrieval-Augmented Image Captioning PromptsToggle child pages in navigation Usage Pattern Completion prompts Chat prompts Accessing/Customizing Prompts within Higher-Level Modules Advanced Prompt Techniques (Variable Mappings, Functions) Prompt Engineering for RAG “Optimization by Prompting” for RAG EmotionPrompt in RAG LoadingToggle child pages in navigation Data Connectors (LlamaHub)Toggle child pages in navigation Module GuidesToggle child pages in navigation Simple Directory Reader Psychic Reader DeepLake Reader Qdrant Reader Discord Reader MongoDB Reader Chroma Reader MyScale Reader Faiss Reader Obsidian Reader Slack Reader Web Page Reader Pinecone Reader Mbox Reader MilvusReader Notion Reader Github Repo Reader Google Docs Reader Database Reader Twitter Reader Weaviate Reader Make Reader Deplot Reader Demo Documents / Nodes Node Parser Usage Pattern Module GuidesToggle child pages in navigation Simple Directory Reader Psychic Reader DeepLake Reader Qdrant Reader Discord Reader MongoDB Reader Chroma Reader MyScale Reader Faiss Reader Obsidian Reader Slack Reader Web Page Reader Pinecone Reader Mbox Reader MilvusReader Notion Reader Github Repo Reader Google Docs Reader Database Reader Twitter Reader Weaviate Reader Make Reader Deplot Reader Demo Documents / Nodes Node Parser IndexingToggle child pages in navigation How Each Index Works Usage PatternToggle child pages in navigation Metadata Extraction Document Management Summary Index Tree Index Keyword Table Index Knowledge Graph Index Custom Retriever combining KG Index and VectorStore Index Knowledge Graph Query Engine Knowledge Graph RAG Query Engine REBEL + Knowledge Graph Index REBEL + Wikipedia Filtering SQL Index SQL Query Engine with LlamaIndex + DuckDB ComposabilityToggle child pages in navigation Composable Graph Basic Composable Graph with Weaviate Composable Graph How Each Index Works Usage PatternToggle child pages in navigation Metadata Extraction Document Management Module GuidesToggle child pages in navigation Vector Store Index Summary Index Tree Index Keyword Table Index Knowledge Graph Index Custom Retriever combining KG Index and VectorStore Index Knowledge Graph Query Engine Knowledge Graph RAG Query Engine REBEL + Knowledge Graph Index REBEL + Wikipedia Filtering SQL Index SQL Query Engine with LlamaIndex + DuckDB Document Summary Index ComposabilityToggle child pages in navigation Composable Graph Basic Composable Graph with Weaviate Composable Graph StoringToggle child pages in navigation Customizing Storage Persisting & Loading Data Vector StoresToggle child pages in navigation Astra DB Simple Vector Store - Async Index Creation Azure CosmosDB MongoDB Vector Store Cassandra Vector Store Chroma Azure Cognitive Search Basic Example Create Index (if it does not exist) Use Existing Index Adding a document to existing index Filtering DashVector Vector Store DeepLake Vector Store DocArray Hnsw Vector Store DocArray InMemory Vector Store Epsilla Vector Store LanceDB Vector Store Metal Vector Store Milvus Vector Store MyScale Vector Store Elasticsearch Vector Store Faiss Vector Store MongoDB Atlas Neo4j vector store Opensearch Vector Store Pinecone Vector Store Redis Vector Store Query the data Working with Metadata Qdrant Vector Store Rockset Vector Store Simple Vector Store Supabase Vector Store Tair Vector Store Tencent Cloud VectorDB Timescale Vector Store (PostgreSQL) Weaviate Vector Store Zep Vector Store Create a Zep Vector Store and Index Querying with Metadata filters Document Stores Index Stores Key-Value Stores Using Graph StoresToggle child pages in navigation Neo4j Graph Store Nebula Graph Store Kuzu Graph Store FalkorDB Graph Store Customizing Storage Persisting & Loading Data Vector StoresToggle child pages in navigation Astra DB Simple Vector Store - Async Index Creation Azure CosmosDB MongoDB Vector Store Cassandra Vector Store Chroma Azure Cognitive Search Basic Example Create Index (if it does not exist) Use Existing Index Adding a document to existing index Filtering DashVector Vector Store DeepLake Vector Store DocArray Hnsw Vector Store DocArray InMemory Vector Store Epsilla Vector Store LanceDB Vector Store Metal Vector Store Milvus Vector Store MyScale Vector Store Elasticsearch Vector Store Faiss Vector Store MongoDB Atlas Neo4j vector store Opensearch Vector Store Pinecone Vector Store Pinecone Vector Store - Hybrid Search Redis Vector Store Query the data Working with Metadata Qdrant Vector Store Rockset Vector Store Simple Vector Store Supabase Vector Store Tair Vector Store Tencent Cloud VectorDB Timescale Vector Store (PostgreSQL) Weaviate Vector Store Weaviate Vector Store - Hybrid Search Zep Vector Store Create a Zep Vector Store and Index Querying with Metadata filters Document Stores Index Stores Key-Value Stores Using Graph StoresToggle child pages in navigation Neo4j Graph Store Nebula Graph Store Knowledge Graph Query Engine Kuzu Graph Store FalkorDB Graph Store QueryingToggle child pages in navigation Query EngineToggle child pages in navigation Response Modes Streaming Custom Query Engine Retriever Query Engine Text-to-SQL Guide (Query Engine + Retriever) JSON Query Engine Pandas Query Engine Retriever Router Query Engine SQL Router Query Engine SQL Auto Vector Query Engine SQL Join Query Engine [Beta] Text-to-SQL with PGVector Retry Query Engine CitationQueryEngine Joint Tabular/Semantic QA over Tesla 10K Ensemble Query Engine Guide Multi-Document Agents Multi-Document Agents (V1) FLARE Query Engine Supporting ModulesToggle child pages in navigation Chat EngineToggle child pages in navigation ReAct Chat Engine OpenAI Chat Engine Context Chat Engine Condense Question Chat Engine Simple Chat Engine Data AgentsToggle child pages in navigation GPT Builder Demo Single-Turn Multi-Function Calling OpenAI Agents OpenAI Assistant Agent Benchmarking OpenAI Retrieval API (through Assistant Agent) OpenAI Assistant Advanced Retrieval Cookbook ReAct Agent with Query Engine Tools ToolsToggle child pages in navigation LlamaHub Tools Guide RetrieverToggle child pages in navigation Retriever Modes Retriever ModulesToggle child pages in navigation Define Custom Retriever BM25 Hybrid Retriever Simple Fusion Retriever Custom Retriever (KG Index and Vector Store Index) Knowledge Graph RAG Retriever Auto-Retrieval (with Chroma) Auto-Retrieval (with BagelDB) Router Retriever Ensemble Retrieval Guide Auto Merging Retriever Recursive Retriever + Node References Recursive Retriever + Node References + Braintrust Response SynthesizerToggle child pages in navigation Response Synthesis ModulesToggle child pages in navigation Refine Refine with Structured Answer Filtering Tree Summarize RoutersToggle child pages in navigation Node PostprocessorToggle child pages in navigation Node Postprocessor ModulesToggle child pages in navigation Sentence Embedding Optimizer Cohere Rerank LLM Reranker Demonstration (2021 Lyft 10-k) LLM Reranker Demonstration (Great Gatsby) Recency Filtering Time-Weighted Rerank PII Masking Forward/Backward Augmentation LongContextReorder Output Parsing ModulesToggle child pages in navigation Guardrails Output Parsing Langchain Output Parsing Response Modes Streaming Module GuidesToggle child pages in navigation Custom Query Engine Retriever Query Engine Text-to-SQL Guide (Query Engine + Retriever) JSON Query Engine Pandas Query Engine Knowledge Graph Query Engine Knowledge Graph RAG Query Engine Router Query Engine Retriever Router Query Engine Joint QA Summary Query Engine Sub Question Query Engine Multi-Step Query Engine SQL Router Query Engine SQL Auto Vector Query Engine SQL Join Query Engine [Beta] Text-to-SQL with PGVector SQL Query Engine with LlamaIndex + DuckDB Retry Query Engine CitationQueryEngine Recursive Retriever + Query Engine Demo Joint Tabular/Semantic QA over Tesla 10K Recursive Retriever + Document Agents Ensemble Query Engine Guide Sub Question Query Engine Recursive Retriever + Document Agents Multi-Document Agents Multi-Document Agents (V1) FLARE Query Engine Supporting ModulesToggle child pages in navigation HyDE Query Transform Multi-Step Query Engine Chat EngineToggle child pages in navigation ReAct Chat Engine OpenAI Chat Engine Context Chat Engine Condense Question Chat Engine Simple Chat Engine Data AgentsToggle child pages in navigation Build your own OpenAI Agent OpenAI Agent with Query Engine Tools Retrieval-Augmented OpenAI Agent OpenAI Agent + Query Engine Experimental Cookbook OpenAI Agent Query Planning Context-Augmented OpenAI Agent Recursive Retriever + Document Agents Multi-Document Agents GPT Builder Demo Single-Turn Multi-Function Calling OpenAI Agents OpenAI Assistant Agent Benchmarking OpenAI Retrieval API (through Assistant Agent) OpenAI Assistant Advanced Retrieval Cookbook ReAct Agent with Query Engine Tools ToolsToggle child pages in navigation Usage Pattern LlamaHub Tools Guide RetrieverToggle child pages in navigation Retriever Modes Retriever ModulesToggle child pages in navigation Define Custom Retriever BM25 Hybrid Retriever Simple Fusion Retriever Reciprocal Rerank Fusion Retriever Custom Retriever (KG Index and Vector Store Index) Knowledge Graph RAG Retriever Simple Fusion Retriever Reciprocal Rerank Fusion Retriever Auto-Retrieval (with Chroma) Auto-Retrieval (with BagelDB) Recursive Retriever + Query Engine Demo Router Retriever Ensemble Retrieval Guide Auto Merging Retriever Recursive Retriever + Node References Recursive Retriever + Node References + Braintrust Metadata Replacement + Node Sentence Window Text-to-SQL Guide (Query Engine + Retriever) DeepMemory (Activeloop) Response SynthesizerToggle child pages in navigation Refine Refine with Structured Answer Filtering Tree Summarize Pydantic Tree Summarize RoutersToggle child pages in navigation Router Query Engine Retriever Router Query Engine SQL Router Query Engine Router Retriever Node PostprocessorToggle child pages in navigation Sentence Embedding Optimizer Cohere Rerank LLM Reranker Demonstration (2021 Lyft 10-k) LLM Reranker Demonstration (Great Gatsby) Recency Filtering Time-Weighted Rerank PII Masking Forward/Backward Augmentation Metadata Replacement + Node Sentence Window LongContextReorder Output Parsing ModulesToggle child pages in navigation Guardrails Output Parsing Langchain Output Parsing Guidance Pydantic Program Guidance for Sub-Question Query Engine OpenAI Pydantic Program ObservabilityToggle child pages in navigation Wandb Callback Handler Arize Phoenix Tracing Tutorial OpenInference Callback Handler + Arize Phoenix Evaluating Search and Retrieval with Arize Phoenix Evaluating and Tracking with TruLens Quickstart Guide with LlamaIndex + TruLens Colab HoneyHive LlamaIndex Tracer CallbacksToggle child pages in navigation Token Counting Handler Llama Debug Handler Aim Callback Token Counting - Migration Guide Wandb Callback Handler Arize Phoenix Tracing Tutorial OpenInference Callback Handler + Arize Phoenix Evaluating Search and Retrieval with Arize Phoenix Evaluating and Tracking with TruLens Quickstart Guide with LlamaIndex + TruLens Colab HoneyHive LlamaIndex Tracer CallbacksToggle child pages in navigation Token Counting Handler Llama Debug Handler Wandb Callback Handler Aim Callback OpenInference Callback Handler + Arize Phoenix Token Counting - Migration Guide EvaluatingToggle child pages in navigation Faithfulness Evaluator Relevancy Evaluator Guideline Evaluator Correctness Evaluator Embedding Similarity Evaluator LlamaIndex + DeepEval Integration QuestionGeneration BatchEvalRunner - Running Multiple Evaluations Retrieval Evaluation Supporting ModulesToggle child pages in navigation ServiceContext ServiceContext API ReferenceToggle child pages in navigation IndicesToggle child pages in navigation Table Index Structured Store Index Empty Index Querying an IndexToggle child pages in navigation RetrieversToggle child pages in navigation Empty Index Retriever Knowledge Graph Retriever List Retriever Keyword Table Retrievers Tree Retrievers Vector Store Retrievers Transform Retriever Response Synthesizer Query EnginesToggle child pages in navigation Graph Query Engine Multistep Query Engine Transform Query Engine Flare Query Engine Citation Query Engine SQL Query Engine Chat EnginesToggle child pages in navigation Query Bundle Query Transform Node LLM Predictors LLMsToggle child pages in navigation HuggingFaceLLM LangChainLLM Replicate XOrbits Xinference Prompt Templates Embeddings OpenAIEmbedding HuggingFaceEmbedding OptimumEmbedding InstructorEmbedding LangchainEmbedding GoogleUnivSentEncoderEmbedding Node Postprocessor Storage ContextToggle child pages in navigation Document Store Index Store Vector Store KV Storage Loading Indices Composability Data Connectors Service ContextToggle child pages in navigation PromptHelper Callbacks Structured Index Configuration Evaluation Response Playground Finetuning Memory Example Notebooks Langchain Integrations Summary Index Table Index Tree Index Vector Store Index Structured Store Index Knowledge Graph Index Empty Index Querying an IndexToggle child pages in navigation Empty Index Retriever Knowledge Graph Retriever List Retriever Keyword Table Retrievers Tree Retrievers Vector Store Retrievers Transform Retriever Response Synthesizer Query EnginesToggle child pages in navigation Graph Query Engine Multistep Query Engine Retriever Query Engine Transform Query Engine Router Query Engine Retriever Router Query Engine Sub Question Query Engine SQL Join Query Engine Flare Query Engine Citation Query Engine Knowledge Graph Query Engine SQL Query Engine Pandas Query Engine Chat EnginesToggle child pages in navigation Simple Chat Engine Condense Question Chat Engine Query Bundle Query Transform Node LLM Predictors LLMsToggle child pages in navigation OpenAI Azure OpenAI HuggingFaceLLM LangChainLLM Anthropic Gradient Base Model Gradient Model Adapter LiteLLM LlamaCPP PaLM Predibase Replicate XOrbits Xinference Prompt Templates Embeddings OpenAIEmbedding HuggingFaceEmbedding OptimumEmbedding InstructorEmbedding LangchainEmbedding GoogleUnivSentEncoderEmbedding Node Postprocessor Storage ContextToggle child pages in navigation Document Store Index Store Vector Store KV Storage Loading Indices Composability Data Connectors Service ContextToggle child pages in navigation Embeddings OpenAIEmbedding HuggingFaceEmbedding OptimumEmbedding InstructorEmbedding LangchainEmbedding GoogleUnivSentEncoderEmbedding Node Parser PromptHelper LLMsToggle child pages in navigation OpenAI Azure OpenAI HuggingFaceLLM LangChainLLM Anthropic Gradient Base Model Gradient Model Adapter LiteLLM LlamaCPP PaLM Predibase Replicate XOrbits Xinference Callbacks Structured Index Configuration Evaluation Response Playground Finetuning Memory Example Notebooks Langchain Integrations IntegrationsToggle child pages in navigation ObservabilityToggle child pages in navigation Tracing with Graphsignal Unit Testing LLMs With DeepEval Guidance LM Format Enforcer Guardrails OpenAI Function Calling Using Vector StoresToggle child pages in navigation Using Managed IndicesToggle child pages in navigation Vectara Managed Index Using with Langchain 🦜🔗 Streamlit Chainlit LlamaIndex + Ray ChatGPT Plugin Integrations Poe Airbyte Token Counting Handler Llama Debug Handler Wandb Callback Handler Aim Callback OpenInference Callback Handler + Arize Phoenix Token Counting - Migration Guide Tracing with Graphsignal Evaluating and Tracking with TruLens Unit Testing LLMs With DeepEval Guidance LM Format Enforcer Guardrails OpenAI Function Calling Using Vector StoresToggle child pages in navigation Astra DB Simple Vector Store - Async Index Creation Azure CosmosDB MongoDB Vector Store Cassandra Vector Store Chroma Azure Cognitive Search Basic Example Create Index (if it does not exist) Use Existing Index Adding a document to existing index Filtering DashVector Vector Store DeepLake Vector Store DocArray Hnsw Vector Store DocArray InMemory Vector Store Epsilla Vector Store LanceDB Vector Store Metal Vector Store Milvus Vector Store MyScale Vector Store Elasticsearch Vector Store Faiss Vector Store MongoDB Atlas Neo4j vector store Opensearch Vector Store Pinecone Vector Store Pinecone Vector Store - Hybrid Search Redis Vector Store Query the data Working with Metadata Qdrant Vector Store Rockset Vector Store Simple Vector Store Supabase Vector Store Tair Vector Store Tencent Cloud VectorDB Timescale Vector Store (PostgreSQL) Weaviate Vector Store Weaviate Vector Store - Hybrid Search Zep Vector Store Create a Zep Vector Store and Index Querying with Metadata filters Using Graph StoresToggle child pages in navigation Neo4j Graph Store Nebula Graph Store Knowledge Graph Query Engine Kuzu Graph Store FalkorDB Graph Store Using Managed IndicesToggle child pages in navigation Vectara Managed Index Using with Langchain 🦜🔗 Streamlit Chainlit LlamaIndex + Ray ChatGPT Plugin Integrations Poe Airbyte Frequently Asked Questions (FAQ)Toggle child pages in navigation Large Language Models Vector Database Query Engines Chat Engines Documents and Nodes Large Language Models Embeddings Vector Database Query Engines Chat Engines Documents and Nodes Contributing to LlamaIndex Documentation Guide ChangeLog Deprecated Terms Getting and setting prompts for query engines, etc. Defining template variable mappings (e.g. you have an existing QA prompt) Adding few-shot examples + performing query transformations/rewriting. the prompt uses context and question, we expect context_str and query_str Prompt Engineering for RAG Load Data Load into Vector Store Setup Query Engine / Retriever Viewing/Customizing Prompts View Prompts Customize Prompts Try It Out Adding Few-Shot Examples Context Transformations - PII Example Load Data Load into Vector Store Setup Query Engine / Retriever Viewing/Customizing Prompts View Prompts Customize Prompts Try It Out Adding Few-Shot Examples Context Transformations - PII Example Hide navigation sidebar Hide table of contents sidebar Toggle site navigation sidebar Toggle Light / Dark / Auto color theme Toggle table of contents sidebar Search⌘K Installation and Setup How to read these docs Starter Tutorial High-Level Concepts Customization Tutorial Discover LlamaIndex Video Series Use Cases Q&A Chatbots Structured Data Extraction Multi-modalToggle child pages in navigation Understanding Building an LLM application LoadingToggle child pages in navigation Indexing Storing Querying Putting It All TogetherToggle child pages in navigation Tracing and Debugging Optimizing Basic StrategiesToggle child pages in navigation Advanced Retrieval StrategiesToggle child pages in navigation Agentic strategiesToggle child pages in navigation EvaluationToggle child pages in navigation Fine-tuningToggle child pages in navigation Building Performant RAG Applications for ProductionToggle child pages in navigation Building RAG from Scratch (Lower-Level)Toggle child pages in navigation Module Guides ModelsToggle child pages in navigation IndexingToggle child pages in navigation StoringToggle child pages in navigation QueryingToggle child pages in navigation API Reference API ReferenceToggle child pages in navigation Community IntegrationsToggle child pages in navigation Frequently Asked Questions (FAQ)Toggle child pages in navigation Contributing Contributing to LlamaIndex Documentation Guide Changes ChangeLog Deprecated Terms Versions latest stable v0.8.39 v0.8.38 v0.8.37 v0.8.36 v0.8.25 On GitHub View Documentation hosted by Read the Docs Back to top Edit this page Prompt Engineering for RAG In this notebook we show various prompt techniques you can try to customize your LlamaIndex RAG pipeline. Getting and setting prompts for query engines, etc. Defining template variable mappings (e.g. you have an existing QA prompt) Adding few-shot examples + performing query transformations/rewriting. !pip install llama-index Setup Load Data Load into Vector Store Setup Query Engine / Retriever Viewing/Customizing Prompts First, let’s take a look at the query engine prompts, and see how we can customize it. View Prompts Prompt Key: response_synthesizer:text_qa_templateText: Prompt Key: response_synthesizer:refine_templateText: Customize Prompts What if we want to do something different than our standard question-answering prompts? Let’s try out the RAG prompt from LangchainHub One catch is that the template variables in the prompt are different than what’s expected by our synthesizer in the query engine: the prompt uses context and question, we expect context_str and query_str This is not a problem! Let’s add our template variable mappings to map variables. We use our LangchainPromptTemplate to map to LangChain prompts. Try It Out Let’s re-run our query engine again. Adding Few-Shot Examples Let’s try adding few-shot examples to the prompt, which can be dynamically loaded depending on the query! We do this by setting the function_mapping variable in our prompt template - this allows us to compute functions (e.g. return few-shot examples) during prompt formatting time. As an example use case, through this we can coerce the model to output results in a structured format, by showing examples of other structured outputs. Let’s parse a pre-generated question/answer file. For the sake of focus we’ll skip how the file is generated (tl;dr we used a GPT-4 powered function calling RAG pipeline), but the qa pairs look like this: We embed/index these Q/A pairs, and retrieve the top-k. Let’s see what the formatted prompt looks like with the few-shot examples function. (we fill in test context for brevity) Context Transformations - PII Example We can also dynamically add context transformations as functions in the prompt variable. In this example we show how we can process the context_str before feeding to the context window - specifically in masking out PII (a step towards alleviating concerns around data privacy/security). NOTE: You can do these as steps before feeding into the prompt as well, but this gives you flexibility to perform all this on the fly for any QA prompt you define! Next Previous Copyright © 2022, Jerry Liu Made with Sphinx and @pradyunsg's Furo Toggle Light / Dark / Auto color theme Toggle table of contents sidebar Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation Toggle child pages in navigation 🦙⌘ + K 🦙⌘ + K 🦙 ⌘ + K  LlamaIndex 🦙 0.8.68 (../../index.html) (../../index.html) Installation and Setup (../../getting_started/installation.html) How to read these docs (../../getting_started/reading.html) Starter Tutorial (../../getting_started/starter_example.html) High-Level Concepts (../../getting_started/concepts.html) Customization Tutorial (../../getting_started/customization.html) Discover LlamaIndex Video Series (../../getting_started/discover_llamaindex.html) Q&A (../../use_cases/q_and_a.html) Chatbots (../../use_cases/chatbots.html) Agents (../../use_cases/agents.html) Structured Data Extraction (../../use_cases/extraction.html) Multi-modal (../../use_cases/multimodal.html) Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever (../multi_modal/gpt4v_multi_modal_retrieval.html) Multi-modal retrieval with CLIP (../multi_modal/multi_modal_retrieval.html) Retrieval-Augmented Image Captioning (../multi_modal/llava_multi_modal_tesla_10q.html) Building an LLM application (../../understanding/understanding.html) Using LLMs (../../understanding/using_llms/using_llms.html) Privacy and Security (../../understanding/using_llms/privacy.html) Loading (../../understanding/loading/loading.html) LlamaHub (../../understanding/loading/llamahub.html) Indexing (../../understanding/indexing/indexing.html) Storing (../../understanding/storing/storing.html) Querying (../../understanding/querying/querying.html) Putting It All Together (../../understanding/putting_it_all_together/putting_it_all_together.html) Q&A patterns (../../understanding/putting_it_all_together/q_and_a.html) A Guide to Extracting Terms and Definitions (../../understanding/putting_it_all_together/q_and_a/terms_definitions_tutorial.html) A Guide to Creating a Unified Query Framework over your Indexes (../../understanding/putting_it_all_together/q_and_a/unified_query.html) Knowledge Graphs (../../understanding/putting_it_all_together/graphs.html) Structured Data (../../understanding/putting_it_all_together/structured_data.html) A Guide to LlamaIndex + Structured Data (../../understanding/putting_it_all_together/structured_data.html#a-guide-to-llamaindex-structured-data) Airbyte SQL Index Guide (../../understanding/putting_it_all_together/structured_data/Airbyte_demo.html) Full-Stack Web Application (../../understanding/putting_it_all_together/apps.html) A Guide to Building a Full-Stack Web App with LLamaIndex (../../understanding/putting_it_all_together/apps/fullstack_app_guide.html) A Guide to Building a Full-Stack LlamaIndex Web App with Delphic (../../understanding/putting_it_all_together/apps/fullstack_with_delphic.html) How to Build a Chatbot (../../understanding/putting_it_all_together/chatbots/building_a_chatbot.html) Agents (../../understanding/putting_it_all_together/agents.html) Tracing and Debugging (../../understanding/tracing_and_debugging/tracing_and_debugging.html) Evaluating (../../understanding/evaluating/evaluating.html) Cost Analysis (../../understanding/evaluating/cost_analysis/root.html) Usage Pattern (../../understanding/evaluating/cost_analysis/usage_pattern.html) Basic Strategies (../../optimizing/basic_strategies/basic_strategies.html) Accessing/Customizing Prompts within Higher-Level Modules (prompt_mixin.html) Advanced Prompt Techniques (Variable Mappings, Functions) (advanced_prompts.html) Advanced Prompt Techniques (Variable Mappings, Functions) (advanced_prompts.html) Prompt Engineering for RAG (#) BM25 Retriever (../retrievers/bm25_retriever.html) Reciprocal Rerank Fusion Retriever (../retrievers/reciprocal_rerank_fusion.html) Weaviate Vector Store - Hybrid Search (../vector_stores/WeaviateIndexDemo-Hybrid.html) Pinecone Vector Store - Hybrid Search (../vector_stores/PineconeIndexDemo-Hybrid.html) Vector Store Index (../../module_guides/indexing/vector_store_guide.html) Defining and Customizing Documents (../../module_guides/loading/documents_and_nodes/usage_documents.html) Extracting Metadata for Better Document Indexing and Understanding (../metadata_extraction/MetadataExtractionSEC.html) Defining and Customizing Nodes (../../module_guides/loading/documents_and_nodes/usage_nodes.html) Automated Metadata Extraction for Nodes (../../module_guides/loading/documents_and_nodes/usage_metadata_extractor.html) Extracting Metadata for Better Document Indexing and Understanding (../metadata_extraction/MetadataExtractionSEC.html) Automated Metadata Extraction for Better Retrieval + Synthesis (../metadata_extraction/MetadataExtraction_LLMSurvey.html) Entity Metadata Extraction (../metadata_extraction/EntityExtractionClimate.html) Metadata Extraction and Augmentation w/ Marvin (../metadata_extraction/MarvinMetadataExtractorDemo.html) Pydantic Extractor (../metadata_extraction/PydanticExtractor.html) Advanced Retrieval Strategies (../../optimizing/advanced_retrieval/advanced_retrieval.html) Query Transformations (../../optimizing/advanced_retrieval/query_transformations.html) HyDE Query Transform (../query_transformations/HyDEQueryTransformDemo.html) Multi-Step Query Engine (../query_transformations/SimpleIndexDemo-multistep.html) Pydantic Program (../../optimizing/advanced_retrieval/structured_outputs/pydantic_program.html) OpenAI Pydantic Program (../output_parsing/openai_pydantic_program.html) Guidance Pydantic Program (../output_parsing/guidance_pydantic_program.html) Guidance for Sub-Question Query Engine (../output_parsing/guidance_sub_question.html) DataFrame Structured Data Extraction (../output_parsing/df_program.html) Evaporate Demo (../output_parsing/evaporate_program.html) Query Engines + Pydantic Outputs (../../optimizing/advanced_retrieval/structured_outputs/query_engine.html) Query Engine with Pydantic Outputs (../query_engine/pydantic_query_engine.html) Pydantic Tree Summarize (../response_synthesizers/pydantic_tree_summarize.html) Download Data (../response_synthesizers/pydantic_tree_summarize.html#download-data) Structured Outputs (../../optimizing/advanced_retrieval/structured_outputs/structured_outputs.html) Pydantic Program (../../optimizing/advanced_retrieval/structured_outputs/pydantic_program.html) OpenAI Pydantic Program (../output_parsing/openai_pydantic_program.html) Guidance Pydantic Program (../output_parsing/guidance_pydantic_program.html) Guidance for Sub-Question Query Engine (../output_parsing/guidance_sub_question.html) DataFrame Structured Data Extraction (../output_parsing/df_program.html) Evaporate Demo (../output_parsing/evaporate_program.html) Query Engines + Pydantic Outputs (../../optimizing/advanced_retrieval/structured_outputs/query_engine.html) Query Engine with Pydantic Outputs (../query_engine/pydantic_query_engine.html) Pydantic Tree Summarize (../response_synthesizers/pydantic_tree_summarize.html) Download Data (../response_synthesizers/pydantic_tree_summarize.html#download-data) DeepMemory (Activeloop) (../retrievers/deep_memory.html) Agentic strategies (../../optimizing/agentic_strategies/agentic_strategies.html) Build your own OpenAI Agent (../agent/openai_agent.html) OpenAI Agent with Query Engine Tools (../agent/openai_agent_with_query_engine.html) Retrieval-Augmented OpenAI Agent (../agent/openai_agent_retrieval.html) OpenAI Agent + Query Engine Experimental Cookbook (../agent/openai_agent_query_cookbook.html) OpenAI Agent Query Planning (../agent/openai_agent_query_plan.html) Context-Augmented OpenAI Agent (../agent/openai_agent_context_retrieval.html) Evaluation (../../optimizing/evaluation/evaluation.html) End-to-End Evaluation (../../optimizing/evaluation/e2e_evaluation.html) QuestionGeneration (../evaluation/QuestionGeneration.html) BatchEvalRunner - Running Multiple Evaluations (../evaluation/batch_eval.html) Correctness Evaluator (../evaluation/correctness_eval.html) Faithfulness Evaluator (../evaluation/faithfulness_eval.html) Guideline Evaluator (../evaluation/guideline_eval.html) Pairwise Evaluator (../evaluation/pairwise_eval.html) Relevancy Evaluator (../evaluation/relevancy_eval.html) Embedding Similarity Evaluator (../evaluation/semantic_similarity_eval.html) Component Wise Evaluation (../../optimizing/evaluation/component_wise_evaluation.html) BEIR Out of Domain Benchmark (../evaluation/BeirEvaluation.html) HotpotQADistractor Demo (../evaluation/HotpotQADistractor.html) Evaluating (../../module_guides/evaluating/root.html) Usage Pattern (Response Evaluation) (../../module_guides/evaluating/usage_pattern.html) Usage Pattern (Retrieval) (../../module_guides/evaluating/usage_pattern_retrieval.html) Modules (../../module_guides/evaluating/modules.html) Faithfulness Evaluator (../evaluation/faithfulness_eval.html) Relevancy Evaluator (../evaluation/relevancy_eval.html) Guideline Evaluator (../evaluation/guideline_eval.html) Correctness Evaluator (../evaluation/correctness_eval.html) Embedding Similarity Evaluator (../evaluation/semantic_similarity_eval.html) LlamaIndex + DeepEval Integration (../evaluation/Deepeval.html) QuestionGeneration (../evaluation/QuestionGeneration.html) BatchEvalRunner - Running Multiple Evaluations (../evaluation/batch_eval.html) Retrieval Evaluation (../evaluation/retrieval/retriever_eval.html) Component Wise Evaluation (../../optimizing/evaluation/component_wise_evaluation.html) BEIR Out of Domain Benchmark (../evaluation/BeirEvaluation.html) HotpotQADistractor Demo (../evaluation/HotpotQADistractor.html) End-to-End Evaluation (../../optimizing/evaluation/e2e_evaluation.html) QuestionGeneration (../evaluation/QuestionGeneration.html) BatchEvalRunner - Running Multiple Evaluations (../evaluation/batch_eval.html) Correctness Evaluator (../evaluation/correctness_eval.html) Faithfulness Evaluator (../evaluation/faithfulness_eval.html) Guideline Evaluator (../evaluation/guideline_eval.html) Pairwise Evaluator (../evaluation/pairwise_eval.html) Relevancy Evaluator (../evaluation/relevancy_eval.html) Embedding Similarity Evaluator (../evaluation/semantic_similarity_eval.html) Fine-tuning (../../optimizing/fine-tuning/fine-tuning.html) Fine-tuning an Adapter (../finetuning/embeddings/finetune_embedding_adapter.html) Embedding Fine-tuning Guide (../finetuning/embeddings/finetune_embedding.html) Router Fine-tuning (../finetuning/router/router_finetune.html) Embedding Fine-tuning Repo (https://github.com/run-llama/finetune-embedding) Embedding Fine-tuning Blog (https://medium.com/llamaindex-blog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971) GPT-3.5 Fine-tuning Notebook (Colab) (https://colab.research.google.com/drive/1NgyCJVyrC2xcZ5lxt2frTU862v6eJHlc?usp=sharing) GPT-3.5 Fine-tuning Notebook (Notebook link) (../finetuning/openai_fine_tuning.html) Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought (../finetuning/react_agent/react_agent_finetune.html) [WIP] Function Calling Fine-tuning (../finetuning/openai_fine_tuning_functions.html) GPT-3.5 Fine-tuning Notebook (Colab) (https://colab.research.google.com/drive/1vWeJBXdFEObuihO7Z8ui2CAYkdHQORqo?usp=sharing) GPT-3.5 Fine-tuning Notebook (in Repo) (https://github.com/jerryjliu/llama_index/blob/main/experimental/openai_fine_tuning/openai_fine_tuning.ipynb) Fine-tuning with Retrieval Augmentation (../finetuning/knowledge/finetune_retrieval_aug.html) OpenAI Function Calling Fine-tuning (../finetuning/openai_fine_tuning_functions.html) Llama2 Structured Output Fine-tuning (../finetuning/gradient/gradient_structured.html) Fine-tuning to Memorize Knowledge (../finetuning/knowledge/finetune_knowledge.html) Llama 2 Text-to-SQL Fine-tuning (w/ Gradient.AI) (../finetuning/gradient/gradient_fine_tuning.html) Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Repo) (https://github.com/run-llama/modal_finetune_sql) Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Notebook) (https://github.com/run-llama/modal_finetune_sql/blob/main/tutorial.ipynb) Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness) (../finetuning/llm_judge/correctness/finetune_llm_judge_single_grading_correctness.html) Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise) (../finetuning/llm_judge/pairwise/finetune_llm_judge.html) Cross-Encoder Finetuning (../finetuning/cross_encoder_finetuning/cross_encoder_finetuning.html) Finetuning Llama 2 for Text-to-SQL (https://medium.com/llamaindex-blog/easily-finetune-llama-2-for-your-text-to-sql-applications-ecd53640e10d) Finetuning GPT-3.5 to Distill GPT-4 (https://colab.research.google.com/drive/1vWeJBXdFEObuihO7Z8ui2CAYkdHQORqo?usp=sharing) Building Performant RAG Applications for Production (../../optimizing/production_rag.html) Recursive Retriever + Query Engine Demo (../query_engine/pdf_tables/recursive_retriever.html) Document Summary Index (../index_structs/doc_summary/DocSummary.html) Metadata Replacement + Node Sentence Window (../node_postprocessor/MetadataReplacementDemo.html) Auto-Retrieval from a Vector Database (../vector_stores/chroma_auto_retriever.html) Document Summary Index (../index_structs/doc_summary/DocSummary.html) Recursive Retriever + Document Agents (../query_engine/recursive_retriever_agents.html) Comparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval) (../retrievers/auto_vs_recursive_retriever.html) Sub Question Query Engine (../query_engine/sub_question_query_engine.html) Joint QA Summary Query Engine (../query_engine/JointQASummary.html) Recursive Retriever + Document Agents (../query_engine/recursive_retriever_agents.html) Router Query Engine (../query_engine/RouterQueryEngine.html) OpenAI Agent + Query Engine Experimental Cookbook (../agent/openai_agent_query_cookbook.html) OpenAI Agent Query Planning (../agent/openai_agent_query_plan.html) Embedding Fine-tuning Guide (../finetuning/embeddings/finetune_embedding.html) Building RAG from Scratch (Lower-Level) (../../optimizing/building_rag_from_scratch.html) Building Data Ingestion from Scratch (../low_level/ingestion.html) Pinecone (../low_level/ingestion.html#pinecone) OpenAI (../low_level/ingestion.html#openai) Building Retrieval from Scratch (../low_level/retrieval.html) Building RAG from Scratch (Open-source only!) (../low_level/oss_ingestion_retrieval.html) Building a (Very Simple) Vector Store from Scratch (../low_level/vector_store.html) Building Response Synthesis from Scratch (../low_level/response_synthesis.html) Building Evaluation from Scratch (../low_level/evaluation.html) Building a Router from Scratch (../low_level/router.html) Building an Advanced Fusion Retriever from Scratch (../low_level/fusion_retriever.html) Models (../../module_guides/models/models.html) Using LLMs (../../module_guides/models/llms.html) Using LLMs as standalone modules (../../module_guides/models/llms/usage_standalone.html) Customizing LLMs within LlamaIndex Abstractions (../../module_guides/models/llms/usage_custom.html) Available LLM integrations (../../module_guides/models/llms/modules.html) OpenAI (../llm/openai.html) Azure OpenAI (../llm/azure_openai.html) AI21 (../llm/ai21.html) Anthropic (../llm/anthropic.html) Gradient Base Model (../llm/gradient_base_model.html) Gradient Model Adapter (../llm/gradient_model_adapter.html) HuggingFace LLM - Camel-5b (../customization/llms/SimpleIndexDemo-Huggingface_camel.html) HuggingFace LLM - StableLM (../customization/llms/SimpleIndexDemo-Huggingface_stablelm.html) Local Llama2 + VectorStoreIndex (../vector_stores/SimpleIndexDemoLlama-Local.html) EverlyAI (../llm/everlyai.html) LiteLLM (../llm/litellm.html) PaLM (../llm/palm.html) Predibase (../llm/predibase.html) Replicate - Llama 2 13B (../llm/llama_2.html) Replicate - Vicuna 13B (../llm/vicuna.html) Llama2 + VectorStoreIndex (../vector_stores/SimpleIndexDemoLlama2.html) LangChain LLM (../llm/langchain.html) Llama API (../llm/llama_api.html) LlamaCPP (../llm/llama_2_llama_cpp.html) Xorbits Inference (../llm/xinference_local_deployment.html) Monster API LLM Integration into LLamaIndex (../llm/monsterapi.html) RunGPT (../llm/rungpt.html) Setup (../llm/rungpt.html#setup) Portkey (../llm/portkey.html) Anyscale (../llm/anyscale.html) Ollama - Llama 2 7B (../llm/ollama.html) Clarifai LLM (../llm/clarifai.html) Bedrock (../llm/bedrock.html) Connect to Bedrock with Access Keysfrom llama_index.llms import Bedrock (../llm/bedrock.html#connect-to-bedrock-with-access-keysfrom-llama-index-llms-import-bedrock) Getting Started (../llm/vertex.html) Streaming Usage (../llm/vertex.html#streaming-usage) Chat Usage (../llm/vertex.html#chat-usage) Async Chat (../llm/vertex.html#async-chat) Streaming Chat (../llm/vertex.html#streaming-chat) Embeddings (../../module_guides/models/embeddings.html) OpenAI Embeddings (../embeddings/OpenAI.html) Langchain Embeddings (../embeddings/Langchain.html) CohereAI Embeddings (../embeddings/cohereai.html) Gradient Embeddings (../embeddings/gradient.html) Azure OpenAI (../customization/llms/AzureOpenAI.html) Custom Embeddings (../embeddings/custom_embeddings.html) Local Embeddings with HuggingFace (../embeddings/huggingface.html) Elasticsearch Embeddings (../embeddings/elasticsearch.html) Embeddings with Clarifai (../embeddings/clarifai.html) LLMRails Embeddings (../embeddings/llm_rails.html) Text Embedding Inference (../embeddings/text_embedding_inference.html) Google PaLM Embeddings (../embeddings/google_palm.html) Jina Embeddings (../embeddings/jinaai_embeddings.html) Prompts (../../module_guides/models/prompts.html) Usage Pattern (../../module_guides/models/prompts/usage_pattern.html) Completion prompts (../customization/prompts/completion_prompts.html) Chat prompts (../customization/prompts/chat_prompts.html) Accessing/Customizing Prompts within Higher-Level Modules (prompt_mixin.html) Advanced Prompt Techniques (Variable Mappings, Functions) (advanced_prompts.html) Prompt Engineering for RAG (#) “Optimization by Prompting” for RAG (prompt_optimization.html) EmotionPrompt in RAG (emotion_prompt.html) Using local models (../../module_guides/models/llms/local.html) Run Llama2 locally (https://replicate.com/blog/run-llama-locally) Embeddings (../../module_guides/models/embeddings.html) OpenAI Embeddings (../embeddings/OpenAI.html) Langchain Embeddings (../embeddings/Langchain.html) CohereAI Embeddings (../embeddings/cohereai.html) Gradient Embeddings (../embeddings/gradient.html) Azure OpenAI (../customization/llms/AzureOpenAI.html) Custom Embeddings (../embeddings/custom_embeddings.html) Local Embeddings with HuggingFace (../embeddings/huggingface.html) Elasticsearch Embeddings (../embeddings/elasticsearch.html) Embeddings with Clarifai (../embeddings/clarifai.html) LLMRails Embeddings (../embeddings/llm_rails.html) Text Embedding Inference (../embeddings/text_embedding_inference.html) Google PaLM Embeddings (../embeddings/google_palm.html) Jina Embeddings (../embeddings/jinaai_embeddings.html) [Beta] Multi-modal models (../../module_guides/models/multi_modal.html) Multi-Modal LLM using OpenAI GPT-4V model for image reasoning (../multi_modal/openai_multi_modal.html) Multi-Modal LLM using Replicate LlaVa and Fuyu 8B model for image reasoning (../multi_modal/replicate_multi_modal.html) Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles (../multi_modal/multi_modal_retrieval.html) Retrieval-Augmented Image Captioning (../multi_modal/llava_multi_modal_tesla_10q.html) Prompts (../../module_guides/models/prompts.html) Usage Pattern (../../module_guides/models/prompts/usage_pattern.html) Completion prompts (../customization/prompts/completion_prompts.html) Chat prompts (../customization/prompts/chat_prompts.html) Accessing/Customizing Prompts within Higher-Level Modules (prompt_mixin.html) Advanced Prompt Techniques (Variable Mappings, Functions) (advanced_prompts.html) Prompt Engineering for RAG (#) “Optimization by Prompting” for RAG (prompt_optimization.html) EmotionPrompt in RAG (emotion_prompt.html) Loading (../../module_guides/loading/loading.html) Data Connectors (LlamaHub) (../../module_guides/loading/connector/root.html) Usage Pattern (../../module_guides/loading/connector/usage_pattern.html) Module Guides (../../module_guides/loading/connector/modules.html) Simple Directory Reader (../data_connectors/simple_directory_reader.html) Psychic Reader (../data_connectors/PsychicDemo.html) DeepLake Reader (../data_connectors/DeepLakeReader.html) Qdrant Reader (../data_connectors/QdrantDemo.html) Discord Reader (../data_connectors/DiscordDemo.html) MongoDB Reader (../data_connectors/MongoDemo.html) Chroma Reader (../data_connectors/ChromaDemo.html) MyScale Reader (../data_connectors/MyScaleReaderDemo.html) Faiss Reader (../data_connectors/FaissDemo.html) Obsidian Reader (../data_connectors/ObsidianReaderDemo.html) Slack Reader (../data_connectors/SlackDemo.html) Web Page Reader (../data_connectors/WebPageDemo.html) Pinecone Reader (../data_connectors/PineconeDemo.html) Mbox Reader (../data_connectors/MboxReaderDemo.html) MilvusReader (../data_connectors/MilvusReaderDemo.html) Notion Reader (../data_connectors/NotionDemo.html) Github Repo Reader (../data_connectors/GithubRepositoryReaderDemo.html) Google Docs Reader (../data_connectors/GoogleDocsDemo.html) Database Reader (../data_connectors/DatabaseReaderDemo.html) Twitter Reader (../data_connectors/TwitterDemo.html) Weaviate Reader (../data_connectors/WeaviateDemo.html) Make Reader (../data_connectors/MakeDemo.html) Deplot Reader Demo (../data_connectors/deplot/DeplotReader.html) Documents / Nodes (../../module_guides/loading/documents_and_nodes/root.html) Node Parser (../../module_guides/loading/node_parsers/root.html) Indexing (../../module_guides/indexing/indexing.html) How Each Index Works (../../module_guides/indexing/index_guide.html) Usage Pattern (../../module_guides/indexing/usage_pattern.html) Metadata Extraction (../../module_guides/indexing/metadata_extraction.html) Document Management (../../module_guides/indexing/document_management.html) Module Guides (../../module_guides/indexing/modules.html) Vector Store Index (../../module_guides/indexing/vector_store_guide.html) Summary Index (../../module_guides/indexing/index_guide.html) Tree Index (../../module_guides/indexing/index_guide.html) Keyword Table Index (../../module_guides/indexing/index_guide.html) Knowledge Graph Index (../index_structs/knowledge_graph/KnowledgeGraphDemo.html) Custom Retriever combining KG Index and VectorStore Index (../index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html) Knowledge Graph Query Engine (../query_engine/knowledge_graph_query_engine.html) Knowledge Graph RAG Query Engine (../query_engine/knowledge_graph_rag_query_engine.html) REBEL + Knowledge Graph Index (https://colab.research.google.com/drive/1G6pcR0pXvSkdMQlAK_P-IrYgo-_staxd?usp=sharing) REBEL + Wikipedia Filtering (../index_structs/knowledge_graph/knowledge_graph2.html) SQL Index (../index_structs/struct_indices/SQLIndexDemo.html) SQL Query Engine with LlamaIndex + DuckDB (../index_structs/struct_indices/duckdb_sql_query.html) Document Summary Index (../index_structs/doc_summary/DocSummary.html) Composability (../../module_guides/indexing/composability.html) Composable Graph Basic (../composable_indices/ComposableIndices-Prior.html) Composable Graph with Weaviate (../composable_indices/ComposableIndices-Weaviate.html) Composable Graph (../composable_indices/ComposableIndices.html) Storing (../../module_guides/storing/storing.html) Customizing Storage (../../module_guides/storing/customization.html) Persisting & Loading Data (../../module_guides/storing/save_load.html) Vector Stores (../../module_guides/storing/vector_stores.html) Astra DB (../vector_stores/AstraDBIndexDemo.html) Simple Vector Store - Async Index Creation (../vector_stores/AsyncIndexCreationDemo.html) Azure CosmosDB MongoDB Vector Store (../vector_stores/AzureCosmosDBMongoDBvCoreDemo.html) Cassandra Vector Store (../vector_stores/CassandraIndexDemo.html) Chroma (../vector_stores/ChromaIndexDemo.html) Azure Cognitive Search (../vector_stores/CognitiveSearchIndexDemo.html) Basic Example (../vector_stores/CognitiveSearchIndexDemo.html#basic-example) Create Index (if it does not exist) (../vector_stores/CognitiveSearchIndexDemo.html#create-index-if-it-does-not-exist) Use Existing Index (../vector_stores/CognitiveSearchIndexDemo.html#use-existing-index) Adding a document to existing index (../vector_stores/CognitiveSearchIndexDemo.html#adding-a-document-to-existing-index) Filtering (../vector_stores/CognitiveSearchIndexDemo.html#filtering) DashVector Vector Store (../vector_stores/DashvectorIndexDemo.html) DeepLake Vector Store (../vector_stores/DeepLakeIndexDemo.html) DocArray Hnsw Vector Store (../vector_stores/DocArrayHnswIndexDemo.html) DocArray InMemory Vector Store (../vector_stores/DocArrayInMemoryIndexDemo.html) Epsilla Vector Store (../vector_stores/EpsillaIndexDemo.html) LanceDB Vector Store (../vector_stores/LanceDBIndexDemo.html) Metal Vector Store (../vector_stores/MetalIndexDemo.html) Milvus Vector Store (../vector_stores/MilvusIndexDemo.html) MyScale Vector Store (../vector_stores/MyScaleIndexDemo.html) Elasticsearch Vector Store (../vector_stores/ElasticsearchIndexDemo.html) Faiss Vector Store (../vector_stores/FaissIndexDemo.html) MongoDB Atlas (../vector_stores/MongoDBAtlasVectorSearch.html) Neo4j vector store (../vector_stores/Neo4jVectorDemo.html) Opensearch Vector Store (../vector_stores/OpensearchDemo.html) Pinecone Vector Store (../vector_stores/PineconeIndexDemo.html) Pinecone Vector Store - Hybrid Search (../vector_stores/PineconeIndexDemo-Hybrid.html) Redis Vector Store (../vector_stores/RedisIndexDemo.html) Query the data (../vector_stores/RedisIndexDemo.html#query-the-data) Working with Metadata (../vector_stores/RedisIndexDemo.html#working-with-metadata) Qdrant Vector Store (../vector_stores/QdrantIndexDemo.html) Rockset Vector Store (../vector_stores/RocksetIndexDemo.html) Simple Vector Store (../vector_stores/SimpleIndexDemo.html) Supabase Vector Store (../vector_stores/SupabaseVectorIndexDemo.html) Tair Vector Store (../vector_stores/TairIndexDemo.html) Tencent Cloud VectorDB (../vector_stores/TencentVectorDBIndexDemo.html) Timescale Vector Store (PostgreSQL) (../vector_stores/Timescalevector.html) Weaviate Vector Store (../vector_stores/WeaviateIndexDemo.html) Weaviate Vector Store - Hybrid Search (../vector_stores/WeaviateIndexDemo-Hybrid.html) Zep Vector Store (../vector_stores/ZepIndexDemo.html) Create a Zep Vector Store and Index (../vector_stores/ZepIndexDemo.html#create-a-zep-vector-store-and-index) Querying with Metadata filters (../vector_stores/ZepIndexDemo.html#querying-with-metadata-filters) Document Stores (../../module_guides/storing/docstores.html) Index Stores (../../module_guides/storing/index_stores.html) Key-Value Stores (../../module_guides/storing/kv_stores.html) Using Graph Stores (../../community/integrations/graph_stores.html) Neo4j Graph Store (../index_structs/knowledge_graph/Neo4jKGIndexDemo.html) Nebula Graph Store (../index_structs/knowledge_graph/NebulaGraphKGIndexDemo.html) Knowledge Graph Query Engine (../query_engine/knowledge_graph_query_engine.html) Kuzu Graph Store (../index_structs/knowledge_graph/KuzuGraphDemo.html) FalkorDB Graph Store (../index_structs/knowledge_graph/FalkorDBGraphDemo.html) Querying (../../module_guides/querying/querying.html) Query Engine (../../module_guides/deploying/query_engine/root.html) Usage Pattern (../../module_guides/deploying/query_engine/usage_pattern.html) Response Modes (../../module_guides/deploying/query_engine/response_modes.html) Streaming (../../module_guides/deploying/query_engine/streaming.html) Module Guides (../../module_guides/deploying/query_engine/modules.html) Custom Query Engine (../query_engine/custom_query_engine.html) Retriever Query Engine (../query_engine/CustomRetrievers.html) Text-to-SQL Guide (Query Engine + Retriever) (../index_structs/struct_indices/SQLIndexDemo.html) JSON Query Engine (../query_engine/json_query_engine.html) Pandas Query Engine (../query_engine/pandas_query_engine.html) Knowledge Graph Query Engine (../query_engine/knowledge_graph_query_engine.html) Knowledge Graph RAG Query Engine (../query_engine/knowledge_graph_rag_query_engine.html) Router Query Engine (../query_engine/RouterQueryEngine.html) Retriever Router Query Engine (../query_engine/RetrieverRouterQueryEngine.html) Joint QA Summary Query Engine (../query_engine/JointQASummary.html) Sub Question Query Engine (../query_engine/sub_question_query_engine.html) Multi-Step Query Engine (../query_transformations/SimpleIndexDemo-multistep.html) SQL Router Query Engine (../query_engine/SQLRouterQueryEngine.html) SQL Auto Vector Query Engine (../query_engine/SQLAutoVectorQueryEngine.html) SQL Join Query Engine (../query_engine/SQLJoinQueryEngine.html) [Beta] Text-to-SQL with PGVector (../query_engine/pgvector_sql_query_engine.html) SQL Query Engine with LlamaIndex + DuckDB (../index_structs/struct_indices/duckdb_sql_query.html) Retry Query Engine (../evaluation/RetryQuery.html) CitationQueryEngine (../query_engine/citation_query_engine.html) Recursive Retriever + Query Engine Demo (../query_engine/pdf_tables/recursive_retriever.html) Joint Tabular/Semantic QA over Tesla 10K (../query_engine/sec_tables/tesla_10q_table.html) Recursive Retriever + Document Agents (../query_engine/recursive_retriever_agents.html) Ensemble Query Engine Guide (../query_engine/ensemble_query_engine.html) Sub Question Query Engine (../query_engine/sub_question_query_engine.html) Recursive Retriever + Document Agents (../query_engine/recursive_retriever_agents.html) Multi-Document Agents (../agent/multi_document_agents.html) Multi-Document Agents (V1) (../agent/multi_document_agents-v1.html) FLARE Query Engine (../query_engine/flare_query_engine.html) Supporting Modules (../../module_guides/deploying/query_engine/supporting_modules.html) Query Transformations (../../optimizing/advanced_retrieval/query_transformations.html) HyDE Query Transform (../query_transformations/HyDEQueryTransformDemo.html) Multi-Step Query Engine (../query_transformations/SimpleIndexDemo-multistep.html) Chat Engine (../../module_guides/deploying/chat_engines/root.html) Usage Pattern (../../module_guides/deploying/chat_engines/usage_pattern.html) Module Guides (../../module_guides/deploying/chat_engines/modules.html) ReAct Chat Engine (../chat_engine/chat_engine_react.html) OpenAI Chat Engine (../chat_engine/chat_engine_openai.html) Context Chat Engine (../chat_engine/chat_engine_context.html) Condense Question Chat Engine (../chat_engine/chat_engine_condense_question.html) Simple Chat Engine (../chat_engine/chat_engine_repl.html) Data Agents (../../module_guides/deploying/agents/root.html) Usage Pattern (../../module_guides/deploying/agents/usage_pattern.html) Module Guides (../../module_guides/deploying/agents/modules.html) Build your own OpenAI Agent (../agent/openai_agent.html) OpenAI Agent with Query Engine Tools (../agent/openai_agent_with_query_engine.html) Retrieval-Augmented OpenAI Agent (../agent/openai_agent_retrieval.html) OpenAI Agent + Query Engine Experimental Cookbook (../agent/openai_agent_query_cookbook.html) OpenAI Agent Query Planning (../agent/openai_agent_query_plan.html) Context-Augmented OpenAI Agent (../agent/openai_agent_context_retrieval.html) Recursive Retriever + Document Agents (../query_engine/recursive_retriever_agents.html) Multi-Document Agents (../agent/multi_document_agents.html) GPT Builder Demo (../agent/agent_builder.html) Single-Turn Multi-Function Calling OpenAI Agents (../agent/openai_agent_parallel_function_calling.html) OpenAI Assistant Agent (../agent/openai_assistant_agent.html) Benchmarking OpenAI Retrieval API (through Assistant Agent) (../agent/openai_retrieval_benchmark.html) OpenAI Assistant Advanced Retrieval Cookbook (../agent/openai_assistant_query_cookbook.html) ReAct Agent with Query Engine Tools (../agent/react_agent_with_query_engine.html) Tools (../../module_guides/deploying/agents/tools/root.html) Usage Pattern (../../module_guides/deploying/agents/tools/usage_pattern.html) LlamaHub Tools Guide (../../module_guides/deploying/agents/tools/llamahub_tools_guide.html) Retriever (../../module_guides/querying/retriever/root.html) Retriever Modes (../../module_guides/querying/retriever/retriever_modes.html) Retriever Modules (../../module_guides/querying/retriever/retrievers.html) Define Custom Retriever (../query_engine/CustomRetrievers.html) BM25 Hybrid Retriever (../retrievers/bm25_retriever.html) Simple Fusion Retriever (../retrievers/simple_fusion.html) Reciprocal Rerank Fusion Retriever (../retrievers/reciprocal_rerank_fusion.html) Custom Retriever (KG Index and Vector Store Index) (../index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html) Knowledge Graph RAG Retriever (../query_engine/knowledge_graph_rag_query_engine.html) Simple Fusion Retriever (../retrievers/simple_fusion.html) Reciprocal Rerank Fusion Retriever (../retrievers/reciprocal_rerank_fusion.html) Auto-Retrieval (with Chroma) (../vector_stores/chroma_auto_retriever.html) Auto-Retrieval (with BagelDB) (../vector_stores/BagelAutoRetriever.html) Recursive Retriever + Query Engine Demo (../query_engine/pdf_tables/recursive_retriever.html) Router Retriever (../retrievers/router_retriever.html) Ensemble Retrieval Guide (../retrievers/ensemble_retrieval.html) Auto Merging Retriever (../retrievers/auto_merging_retriever.html) Recursive Retriever + Node References (../retrievers/recursive_retriever_nodes.html) Recursive Retriever + Node References + Braintrust (../retrievers/recurisve_retriever_nodes_braintrust.html) Metadata Replacement + Node Sentence Window (../node_postprocessor/MetadataReplacementDemo.html) Text-to-SQL Guide (Query Engine + Retriever) (../index_structs/struct_indices/SQLIndexDemo.html) DeepMemory (Activeloop) (../retrievers/deep_memory.html) Response Synthesizer (../../module_guides/querying/response_synthesizers/root.html) Response Synthesis Modules (../../module_guides/querying/response_synthesizers/response_synthesizers.html) Refine (../response_synthesizers/refine.html) Refine with Structured Answer Filtering (../response_synthesizers/structured_refine.html) Tree Summarize (../response_synthesizers/tree_summarize.html) Pydantic Tree Summarize (../response_synthesizers/custom_prompt_synthesizer.html) Routers (../../module_guides/querying/router/root.html) Router Query Engine (../query_engine/RouterQueryEngine.html) Retriever Router Query Engine (../query_engine/RetrieverRouterQueryEngine.html) SQL Router Query Engine (../query_engine/SQLRouterQueryEngine.html) Router Retriever (../retrievers/router_retriever.html) Node Postprocessor (../../module_guides/querying/node_postprocessors/root.html) Node Postprocessor Modules (../../module_guides/querying/node_postprocessors/node_postprocessors.html) Sentence Embedding Optimizer (../node_postprocessor/OptimizerDemo.html) Cohere Rerank (../node_postprocessor/CohereRerank.html) LLM Reranker Demonstration (2021 Lyft 10-k) (../node_postprocessor/LLMReranker-Lyft-10k.html) LLM Reranker Demonstration (Great Gatsby) (../node_postprocessor/LLMReranker-Gatsby.html) Recency Filtering (../node_postprocessor/RecencyPostprocessorDemo.html) Time-Weighted Rerank (../node_postprocessor/TimeWeightedPostprocessorDemo.html) PII Masking (../node_postprocessor/PII.html) Forward/Backward Augmentation (../node_postprocessor/PrevNextPostprocessorDemo.html) Metadata Replacement + Node Sentence Window (../node_postprocessor/MetadataReplacementDemo.html) LongContextReorder (../node_postprocessor/LongContextReorder.html) Output Parsing Modules (../../module_guides/querying/output_parser.html) Guardrails Output Parsing (../output_parsing/GuardrailsDemo.html) Langchain Output Parsing (../output_parsing/LangchainOutputParserDemo.html) Guidance Pydantic Program (../output_parsing/guidance_pydantic_program.html) Guidance for Sub-Question Query Engine (../output_parsing/guidance_sub_question.html) OpenAI Pydantic Program (../output_parsing/openai_pydantic_program.html) Observability (../../module_guides/observability/observability.html) Wandb Callback Handler (../callbacks/WandbCallbackHandler.html) Arize Phoenix Tracing Tutorial (https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/llama_index_tracing_tutorial.ipynb) OpenInference Callback Handler + Arize Phoenix (../callbacks/OpenInferenceCallback.html) Evaluating Search and Retrieval with Arize Phoenix (https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/llama_index_search_and_retrieval_tutorial.ipynb) Evaluating and Tracking with TruLens (../../community/integrations/trulens.html) Quickstart Guide with LlamaIndex + TruLens (https://github.com/truera/trulens/blob/main/trulens_eval/examples/frameworks/llama_index/llama_index_quickstart.ipynb) Colab (https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/frameworks/llama_index/llama_index_quickstart.ipynb) HoneyHive LlamaIndex Tracer (../callbacks/HoneyHiveLlamaIndexTracer.html) Callbacks (../../module_guides/observability/callbacks/root.html) Token Counting Handler (../callbacks/TokenCountingHandler.html) Llama Debug Handler (../callbacks/LlamaDebugHandler.html) Wandb Callback Handler (../callbacks/WandbCallbackHandler.html) Aim Callback (../callbacks/AimCallback.html) OpenInference Callback Handler + Arize Phoenix (../callbacks/OpenInferenceCallback.html) Token Counting - Migration Guide (../../module_guides/observability/callbacks/token_counting_migration.html) Evaluating (../../module_guides/evaluating/root.html) Usage Pattern (Response Evaluation) (../../module_guides/evaluating/usage_pattern.html) Usage Pattern (Retrieval) (../../module_guides/evaluating/usage_pattern_retrieval.html) Modules (../../module_guides/evaluating/modules.html) Faithfulness Evaluator (../evaluation/faithfulness_eval.html) Relevancy Evaluator (../evaluation/relevancy_eval.html) Guideline Evaluator (../evaluation/guideline_eval.html) Correctness Evaluator (../evaluation/correctness_eval.html) Embedding Similarity Evaluator (../evaluation/semantic_similarity_eval.html) LlamaIndex + DeepEval Integration (../evaluation/Deepeval.html) QuestionGeneration (../evaluation/QuestionGeneration.html) BatchEvalRunner - Running Multiple Evaluations (../evaluation/batch_eval.html) Retrieval Evaluation (../evaluation/retrieval/retriever_eval.html) Supporting Modules (../../module_guides/supporting_modules/supporting_modules.html) ServiceContext (../../module_guides/supporting_modules/service_context.html) API Reference (../../api_reference/index.html) Indices (../../api_reference/indices.html) Summary Index (../../api_reference/indices/list.html) Table Index (../../api_reference/indices/table.html) Tree Index (../../api_reference/indices/tree.html) Vector Store Index (../../api_reference/indices/vector_store.html) Structured Store Index (../../api_reference/indices/struct_store.html) Knowledge Graph Index (../../api_reference/indices/kg.html) Empty Index (../../api_reference/indices/empty.html) Querying an Index (../../api_reference/query.html) Retrievers (../../api_reference/query/retrievers.html) Empty Index Retriever (../../api_reference/query/retrievers/empty.html) Knowledge Graph Retriever (../../api_reference/query/retrievers/kg.html) List Retriever (../../api_reference/query/retrievers/list.html) Keyword Table Retrievers (../../api_reference/query/retrievers/table.html) Tree Retrievers (../../api_reference/query/retrievers/tree.html) Vector Store Retrievers (../../api_reference/query/retrievers/vector_store.html) Transform Retriever (../../api_reference/query/retrievers/transform.html) Response Synthesizer (../../api_reference/query/response_synthesizer.html) Query Engines (../../api_reference/query/query_engines.html) Graph Query Engine (../../api_reference/query/query_engines/graph_query_engine.html) Multistep Query Engine (../../api_reference/query/query_engines/multistep_query_engine.html) Retriever Query Engine (../../api_reference/query/query_engines/retriever_query_engine.html) Transform Query Engine (../../api_reference/query/query_engines/transform_query_engine.html) Router Query Engine (../../api_reference/query/query_engines/router_query_engine.html) Retriever Router Query Engine (../../api_reference/query/query_engines/retriever_router_query_engine.html) Sub Question Query Engine (../../api_reference/query/query_engines/sub_question_query_engine.html) SQL Join Query Engine (../../api_reference/query/query_engines/sql_join_query_engine.html) Flare Query Engine (../../api_reference/query/query_engines/flare_query_engine.html) Citation Query Engine (../../api_reference/query/query_engines/citation_query_engine.html) Knowledge Graph Query Engine (../../api_reference/query/query_engines/knowledge_graph_query_engine.html) SQL Query Engine (../../api_reference/query/query_engines/sql_query_engine.html) Pandas Query Engine (../../api_reference/query/query_engines/pandas_query_engine.html) Chat Engines (../../api_reference/query/chat_engines.html) Simple Chat Engine (../../api_reference/query/chat_engines/simple_chat_engine.html) Condense Question Chat Engine (../../api_reference/query/chat_engines/condense_question_chat_engine.html) Query Bundle (../../api_reference/query/query_bundle.html) Query Transform (../../api_reference/query/query_transform.html) Node (../../api_reference/node.html) LLM Predictors (../../api_reference/llm_predictor.html) LLMs (../../api_reference/llms.html) OpenAI (../../api_reference/llms/openai.html) Azure OpenAI (../../api_reference/llms/azure_openai.html) HuggingFaceLLM (../../api_reference/llms/huggingface.html) LangChainLLM (../../api_reference/llms/langchain.html) Anthropic (../../api_reference/llms/anthropic.html) Gradient Base Model (../../api_reference/llms/gradient_base_model.html) Gradient Model Adapter (../../api_reference/llms/gradient_model_adapter.html) LiteLLM (../../api_reference/llms/litellm.html) LlamaCPP (../../api_reference/llms/llama_cpp.html) PaLM (../../api_reference/llms/palm.html) Predibase (../../api_reference/llms/predibase.html) Replicate (../../api_reference/llms/replicate.html) XOrbits Xinference (../../api_reference/llms/xinference.html) Prompt Templates (../../api_reference/prompts.html) Embeddings (../../api_reference/service_context/embeddings.html) OpenAIEmbedding (../../api_reference/service_context/embeddings.html#openaiembedding) HuggingFaceEmbedding (../../api_reference/service_context/embeddings.html#huggingfaceembedding) OptimumEmbedding (../../api_reference/service_context/embeddings.html#optimumembedding) InstructorEmbedding (../../api_reference/service_context/embeddings.html#instructorembedding) LangchainEmbedding (../../api_reference/service_context/embeddings.html#langchainembedding) GoogleUnivSentEncoderEmbedding (../../api_reference/service_context/embeddings.html#googleunivsentencoderembedding) Node Postprocessor (../../api_reference/node_postprocessor.html) Storage Context (../../api_reference/storage.html) Document Store (../../api_reference/storage/docstore.html) Index Store (../../api_reference/storage/index_store.html) Vector Store (../../api_reference/storage/vector_store.html) KV Storage (../../api_reference/storage/kv_store.html) Loading Indices (../../api_reference/storage/indices_save_load.html) Composability (../../api_reference/composability.html) Data Connectors (../../api_reference/readers.html) Service Context (../../api_reference/service_context.html) Embeddings (../../api_reference/service_context/embeddings.html) OpenAIEmbedding (../../api_reference/service_context/embeddings.html#openaiembedding) HuggingFaceEmbedding (../../api_reference/service_context/embeddings.html#huggingfaceembedding) OptimumEmbedding (../../api_reference/service_context/embeddings.html#optimumembedding) InstructorEmbedding (../../api_reference/service_context/embeddings.html#instructorembedding) LangchainEmbedding (../../api_reference/service_context/embeddings.html#langchainembedding) GoogleUnivSentEncoderEmbedding (../../api_reference/service_context/embeddings.html#googleunivsentencoderembedding) Node Parser (../../api_reference/service_context/node_parser.html) PromptHelper (../../api_reference/service_context/prompt_helper.html) LLMs (../../api_reference/llms.html) OpenAI (../../api_reference/llms/openai.html) Azure OpenAI (../../api_reference/llms/azure_openai.html) HuggingFaceLLM (../../api_reference/llms/huggingface.html) LangChainLLM (../../api_reference/llms/langchain.html) Anthropic (../../api_reference/llms/anthropic.html) Gradient Base Model (../../api_reference/llms/gradient_base_model.html) Gradient Model Adapter (../../api_reference/llms/gradient_model_adapter.html) LiteLLM (../../api_reference/llms/litellm.html) LlamaCPP (../../api_reference/llms/llama_cpp.html) PaLM (../../api_reference/llms/palm.html) Predibase (../../api_reference/llms/predibase.html) Replicate (../../api_reference/llms/replicate.html) XOrbits Xinference (../../api_reference/llms/xinference.html) Callbacks (../../api_reference/callbacks.html) Structured Index Configuration (../../api_reference/struct_store.html) Evaluation (../../api_reference/evaluation.html) Response (../../api_reference/response.html) Playground (../../api_reference/playground.html) Finetuning (../../api_reference/finetuning.html) Memory (../../api_reference/memory.html) Example Notebooks (../../api_reference/example_notebooks.html) Langchain Integrations (../../api_reference/langchain_integrations/base.html) Integrations (../../community/integrations.html) Observability (../../module_guides/observability/observability.html) Wandb Callback Handler (../callbacks/WandbCallbackHandler.html) Arize Phoenix Tracing Tutorial (https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/llama_index_tracing_tutorial.ipynb) OpenInference Callback Handler + Arize Phoenix (../callbacks/OpenInferenceCallback.html) Evaluating Search and Retrieval with Arize Phoenix (https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/llama_index_search_and_retrieval_tutorial.ipynb) Evaluating and Tracking with TruLens (../../community/integrations/trulens.html) Quickstart Guide with LlamaIndex + TruLens (https://github.com/truera/trulens/blob/main/trulens_eval/examples/frameworks/llama_index/llama_index_quickstart.ipynb) Colab (https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/frameworks/llama_index/llama_index_quickstart.ipynb) HoneyHive LlamaIndex Tracer (../callbacks/HoneyHiveLlamaIndexTracer.html) Callbacks (../../module_guides/observability/callbacks/root.html) Token Counting Handler (../callbacks/TokenCountingHandler.html) Llama Debug Handler (../callbacks/LlamaDebugHandler.html) Wandb Callback Handler (../callbacks/WandbCallbackHandler.html) Aim Callback (../callbacks/AimCallback.html) OpenInference Callback Handler + Arize Phoenix (../callbacks/OpenInferenceCallback.html) Token Counting - Migration Guide (../../module_guides/observability/callbacks/token_counting_migration.html) Tracing with Graphsignal (../../community/integrations/graphsignal.html) Evaluating and Tracking with TruLens (../../community/integrations/trulens.html) Unit Testing LLMs With DeepEval (../../community/integrations/deepeval.html) Guidance (../../community/integrations/guidance.html) LM Format Enforcer (../../community/integrations/lmformatenforcer.html) Guardrails (../output_parsing/GuardrailsDemo.html) OpenAI Function Calling (../output_parsing/openai_pydantic_program.html) Using Vector Stores (../../community/integrations/vector_stores.html) Astra DB (../vector_stores/AstraDBIndexDemo.html) Simple Vector Store - Async Index Creation (../vector_stores/AsyncIndexCreationDemo.html) Azure CosmosDB MongoDB Vector Store (../vector_stores/AzureCosmosDBMongoDBvCoreDemo.html) Cassandra Vector Store (../vector_stores/CassandraIndexDemo.html) Chroma (../vector_stores/ChromaIndexDemo.html) Azure Cognitive Search (../vector_stores/CognitiveSearchIndexDemo.html) Basic Example (../vector_stores/CognitiveSearchIndexDemo.html#basic-example) Create Index (if it does not exist) (../vector_stores/CognitiveSearchIndexDemo.html#create-index-if-it-does-not-exist) Use Existing Index (../vector_stores/CognitiveSearchIndexDemo.html#use-existing-index) Adding a document to existing index (../vector_stores/CognitiveSearchIndexDemo.html#adding-a-document-to-existing-index) Filtering (../vector_stores/CognitiveSearchIndexDemo.html#filtering) DashVector Vector Store (../vector_stores/DashvectorIndexDemo.html) DeepLake Vector Store (../vector_stores/DeepLakeIndexDemo.html) DocArray Hnsw Vector Store (../vector_stores/DocArrayHnswIndexDemo.html) DocArray InMemory Vector Store (../vector_stores/DocArrayInMemoryIndexDemo.html) Epsilla Vector Store (../vector_stores/EpsillaIndexDemo.html) LanceDB Vector Store (../vector_stores/LanceDBIndexDemo.html) Metal Vector Store (../vector_stores/MetalIndexDemo.html) Milvus Vector Store (../vector_stores/MilvusIndexDemo.html) MyScale Vector Store (../vector_stores/MyScaleIndexDemo.html) Elasticsearch Vector Store (../vector_stores/ElasticsearchIndexDemo.html) Faiss Vector Store (../vector_stores/FaissIndexDemo.html) MongoDB Atlas (../vector_stores/MongoDBAtlasVectorSearch.html) Neo4j vector store (../vector_stores/Neo4jVectorDemo.html) Opensearch Vector Store (../vector_stores/OpensearchDemo.html) Pinecone Vector Store (../vector_stores/PineconeIndexDemo.html) Pinecone Vector Store - Hybrid Search (../vector_stores/PineconeIndexDemo-Hybrid.html) Redis Vector Store (../vector_stores/RedisIndexDemo.html) Query the data (../vector_stores/RedisIndexDemo.html#query-the-data) Working with Metadata (../vector_stores/RedisIndexDemo.html#working-with-metadata) Qdrant Vector Store (../vector_stores/QdrantIndexDemo.html) Rockset Vector Store (../vector_stores/RocksetIndexDemo.html) Simple Vector Store (../vector_stores/SimpleIndexDemo.html) Supabase Vector Store (../vector_stores/SupabaseVectorIndexDemo.html) Tair Vector Store (../vector_stores/TairIndexDemo.html) Tencent Cloud VectorDB (../vector_stores/TencentVectorDBIndexDemo.html) Timescale Vector Store (PostgreSQL) (../vector_stores/Timescalevector.html) Weaviate Vector Store (../vector_stores/WeaviateIndexDemo.html) Weaviate Vector Store - Hybrid Search (../vector_stores/WeaviateIndexDemo-Hybrid.html) Zep Vector Store (../vector_stores/ZepIndexDemo.html) Create a Zep Vector Store and Index (../vector_stores/ZepIndexDemo.html#create-a-zep-vector-store-and-index) Querying with Metadata filters (../vector_stores/ZepIndexDemo.html#querying-with-metadata-filters) Using Graph Stores (../../community/integrations/graph_stores.html) Neo4j Graph Store (../index_structs/knowledge_graph/Neo4jKGIndexDemo.html) Nebula Graph Store (../index_structs/knowledge_graph/NebulaGraphKGIndexDemo.html) Knowledge Graph Query Engine (../query_engine/knowledge_graph_query_engine.html) Kuzu Graph Store (../index_structs/knowledge_graph/KuzuGraphDemo.html) FalkorDB Graph Store (../index_structs/knowledge_graph/FalkorDBGraphDemo.html) Using Managed Indices (../../community/integrations/managed_indices.html) Vectara Managed Index (../managed/vectaraDemo.html) Using with Langchain 🦜🔗 (../../community/integrations/using_with_langchain.html) Streamlit (https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/) Chainlit (https://docs.chainlit.io/integrations/llama-index) LlamaIndex + Ray (https://www.anyscale.com/blog/build-and-scale-a-powerful-query-engine-with-llamaindex-ray) ChatGPT Plugin Integrations (../../community/integrations/chatgpt_plugins.html) Poe (https://github.com/poe-platform/poe-protocol/tree/main/llama_poe) Airbyte (https://airbyte.com/tutorials/airbyte-and-llamaindex-elt-and-chat-with-your-data-warehouse-without-writing-sql) Frequently Asked Questions (FAQ) (../../community/frequently_asked_questions.html) Large Language Models (../../community/faq/llms.html) Embeddings (../../community/faq/embeddings.html) Vector Database (../../community/faq/vector_database.html) Query Engines (../../community/faq/query_engines.html) Chat Engines (../../community/faq/chat_engines.html) Documents and Nodes (../../community/faq/documents_and_nodes.html) Contributing to LlamaIndex (../../contributing/contributing.html) Documentation Guide (../../contributing/documentation.html) ChangeLog (../../changes/changelog.html) Deprecated Terms (../../changes/deprecated_terms.html) latest (https://docs.llamaindex.ai/en/latest/examples/prompts/prompts_rag.html) stable (https://docs.llamaindex.ai/en/stable/examples/prompts/prompts_rag.html) v0.8.39 (https://docs.llamaindex.ai/en/v0.8.39/examples/prompts/prompts_rag.html) v0.8.38 (https://docs.llamaindex.ai/en/v0.8.38/examples/prompts/prompts_rag.html) v0.8.37 (https://docs.llamaindex.ai/en/v0.8.37/examples/prompts/prompts_rag.html) v0.8.36 (https://docs.llamaindex.ai/en/v0.8.36/examples/prompts/prompts_rag.html) v0.8.25 (https://docs.llamaindex.ai/en/v0.8.25/examples/prompts/prompts_rag.html) View (https://github.com/run-llama/llama_index/blob/99c6e14c747b13d319e18c5dd5df476a913b81f5/docs/examples/prompts/prompts_rag.ipynb) Read the Docs (https://readthedocs.com) (#) (https://github.com/run-llama/llama_index/edit/99c6e14c747b13d319e18c5dd5df476a913b81f5/docs/examples/prompts/prompts_rag.ipynb)  (https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/prompts/prompts_rag.ipynb)  (#prompt-engineering-for-rag)  (#setup)  (#load-data)  (#load-into-vector-store)  (#setup-query-engine-retriever)  (#viewing-customizing-prompts)  (#view-prompts)  (#customize-prompts) LangchainHub (https://smith.langchain.com/hub/rlm/rag-prompt)  (#try-it-out)  (#adding-few-shot-examples)  (#context-transformations-pii-example) (../retrievers/bm25_retriever.html) (advanced_prompts.html) Sphinx (https://www.sphinx-doc.org/) @pradyunsg (https://pradyunsg.me) Furo (https://github.com/pradyunsg/furo) (https://readthedocs.org/projects/llamaindex-llamaindex) (https://github.com/run-llama/llama_index) Prompt Engineering for RAG (#) Setup (#setup) Load Data (#load-data) Load into Vector Store (#load-into-vector-store) Setup Query Engine / Retriever (#setup-query-engine-retriever) Viewing/Customizing Prompts (#viewing-customizing-prompts) View Prompts (#view-prompts) Customize Prompts (#customize-prompts) Try It Out (#try-it-out) Adding Few-Shot Examples (#adding-few-shot-examples) Context Transformations - PII Example (#context-transformations-pii-example)